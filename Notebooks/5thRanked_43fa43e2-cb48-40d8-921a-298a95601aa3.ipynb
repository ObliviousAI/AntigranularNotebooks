{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìä **Antigranular** Heart Disease Prediction Contest (ft. **Harvard/OpenDP** and **TPDP**)\n",
        "\n",
        "üéâ Welcome to a new [Antigranular](https://antigranular.com) contest in collaboration with the [TPDP Workshop](https://tpdp.journalprivacyconfidentiality.org/2024/) and [Harvard's OpenDP Community Meeting](https://opendp.org/)!\n",
        "\n",
        "ü©∫ This time, we are focusing on [heart condition detection](https://en.wikipedia.org/wiki/Cardiovascular_disease) using our new [TensorFlow Privacy](https://github.com/tensorflow/privacy) and [Opacus (PyTorch)](https://opacus.ai/) models!\n",
        "\n",
        "ü¶ú Any questions? Head over to our [Discord](https://discord.com/invite/KJwApgXs4s)!\n",
        "\n"
      ],
      "metadata": {
        "id": "5az73vDZvCWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèÉ‚Äç‚ôÇÔ∏è Getting Started\n",
        "\n",
        "In this section we will download the antigranular package and login\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BZ1S_Qc0v5hL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üì¶ Install Antigranular\n",
        "\n",
        "This command installs the [Antigranular PyPI Package](https://pypi.org/project/antigranular/) on the local enviroment.\n"
      ],
      "metadata": {
        "id": "6_ISjJv_eppS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5uFCyt-Puq4K"
      },
      "outputs": [],
      "source": [
        "# Install the Antigranular package\n",
        "!pip install antigranular &> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úç Login to the Enclave\n",
        "\n",
        "Head over to [Competitions](https://www.antigranular.com/competitions) to find your `<user_id>`, `<user_secret>` and the competition's name and copy that command here.\n",
        "\n",
        "![img](https://docs.antigranular.com/shots/comp_cell.png)"
      ],
      "metadata": {
        "id": "v7jLQa6Uehks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import antigranular as ag\n",
        "session = ag.login(<client_id>,<client_secret>, competition = \"Heart Disease Prediction Hackathon\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "w_JcMMSMv_Ze",
        "outputId": "023ff082-26bf-4dda-8593-7a6a96966f82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset \"Heart Disease Prediction Hackathon Dataset\" loaded to the kernel as \u001b[92mheart_disease_prediction_hackathon_dataset\u001b[0m\n",
            "Key Name                       Value Type     \n",
            "---------------------------------------------\n",
            "train_y                        PrivateDataFrame\n",
            "train_x                        PrivateDataFrame\n",
            "test_x                         DataFrame      \n",
            "\n",
            "Connected to Antigranular server session id: 43fa43e2-cb48-40d8-921a-298a95601aa3, the session will time out if idle for 25 minutes\n",
            "Cell magic '%%ag' registered successfully, use `%%ag` in a notebook cell to execute your python code on Antigranular private python server\n",
            "üöÄ Everything's set up and ready to roll!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ü§ñ Using AG\n",
        "\n",
        "You can now simply use ``%%ag`` to run code on an enclave! You can always head over to our [Docs](https://docs.antigranular.com/) to learn more about AG, but for now, we can define train and test variables as follows."
      ],
      "metadata": {
        "id": "Jeg6W7fPNHhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "x_train = heart_disease_prediction_hackathon_dataset[\"train_x\"]\n",
        "y_train = heart_disease_prediction_hackathon_dataset[\"train_y\"]\n",
        "x_test = heart_disease_prediction_hackathon_dataset[\"test_x\"]"
      ],
      "metadata": {
        "id": "8IHVwjFKk2Ys"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üïµÔ∏è‚Äç‚ôÇÔ∏è Exploring data\n",
        "\n",
        "Exploring data in Antigranular involves spending your epsilon budget, be mindful of your usage but remember that the less epsilon you use, the less accurate your results will get!"
      ],
      "metadata": {
        "id": "4oMW3Eh8RDl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "x_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMiVe3n_t4um",
        "outputId": "920307dc-dd31-4926-f4d7-dea69875d3e2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+-------------+---------------+---------+------------+\n",
            "|    | Column   | numerical   | categorical   | dtype   | bounds     |\n",
            "|----+----------+-------------+---------------+---------+------------|\n",
            "|  0 | age      | True        | False         | int64   | (21, 86)   |\n",
            "|  1 | sex      | True        | False         | int64   | (0, 1)     |\n",
            "|  2 | bp       | True        | False         | int64   | (80, 215)  |\n",
            "|  3 | ch       | True        | False         | int64   | (102, 597) |\n",
            "|  4 | bs       | True        | False         | int64   | (67, 157)  |\n",
            "|  5 | phr      | True        | False         | int64   | (62, 222)  |\n",
            "+----+----------+-------------+---------------+---------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "y_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG3HnW1Ut8X2",
        "outputId": "4a3b5ccd-70c1-491c-bfa1-184939d9cc69"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+-------------+---------------+---------+----------+\n",
            "|    | Column    | numerical   | categorical   | dtype   | bounds   |\n",
            "|----+-----------+-------------+---------------+---------+----------|\n",
            "|  0 | condition | True        | False         | int64   | (0, 1)   |\n",
            "+----+-----------+-------------+---------------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "# We can start by exploring the data, carefully using our epsilon\n",
        "describe = x_train.describe(eps=0.1)\n",
        "ag_print(describe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QNyLhdXmYs5",
        "outputId": "9d265ad3-2309-480a-b536-17f92a220d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               age          sex  ...           bs          phr\n",
            "count  8016.000000  7885.000000  ...  7774.000000  8077.000000\n",
            "mean     59.237499     0.726286  ...    98.681172   143.758544\n",
            "std       5.315081     0.444097  ...    11.489598    13.397244\n",
            "min      21.000000     0.000000  ...    67.000000    62.000000\n",
            "25%      24.469890     0.000689  ...    77.201568   138.840002\n",
            "50%      60.522819     0.976855  ...    94.001013   138.864569\n",
            "75%      47.156685     0.890680  ...   117.633120   176.605836\n",
            "max      80.664432     0.998731  ...   124.144124   190.977667\n",
            "\n",
            "[8 rows x 6 columns]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "# We can start by exploring the data, carefully using our epsilon\n",
        "describe = y_train.describe(eps=0.1)\n",
        "ag_print(describe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ4MX9Ghs2z6",
        "outputId": "fa2b17a7-186c-4919-a6b1-cfc1227d942f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         condition\n",
            "count  8014.000000\n",
            "mean      0.537660\n",
            "std       0.469280\n",
            "min       0.000000\n",
            "25%       0.015925\n",
            "50%       0.999878\n",
            "75%       0.931988\n",
            "max       0.987946\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "# x_test is a public test set, so we can print it without using epsilon\n",
        "ag_print(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OymOmMhqmzpK",
        "outputId": "c2407882-5771-454d-d517-c00d3b27e56f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      age  sex   bp   ch   bs  phr\n",
            "0      71    1  128  326   95  117\n",
            "1      61    1  153  270   98  123\n",
            "2      59    1  113  236  106  181\n",
            "3      69    0  109  151  109  108\n",
            "4      55    0  137  235  101  150\n",
            "...   ...  ...  ...  ...  ...  ...\n",
            "1995   60    1  128  261  112  143\n",
            "1996   50    1  143  216   94  100\n",
            "1997   64    1  120  172   87  142\n",
            "1998   56    1  158  294   82  144\n",
            "1999   69    0  117  559  112  157\n",
            "\n",
            "[2000 rows x 6 columns]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N2Bg6uXag8KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STANDARD SCALING\n",
        "%%ag\n",
        "\n",
        "Most critical point I added to this study, reviewing in your documentation over Antigranular introduction and finding\n",
        "\n",
        "StandardScaler in op_diffprivlib.models (>>>>>from op_diffprivlib.models import StandardScaler)\n",
        "\n",
        "which has fit_transform and transform methods seperately.\n",
        "\n",
        "The one from op_pandas import standard_scaler\n",
        "\n",
        "does not have fit_transform and transform methods. In here it is mandatory create two seperate standard_scaler objects that deteriorate data consistency and cause discrepancy for the train_set and test_set. For allowing model learns on the same transformed scale, test_set should be transformed with StandardScale object fitted through train_set.\n",
        "\n",
        "In the data management, data consistency is very important I guess. I am not theoretician but this point I think settled under this scope."
      ],
      "metadata": {
        "id": "vhGBAQ64g9zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "from op_diffprivlib.models import LinearRegression,RandomForestClassifier,LogisticRegression,StandardScaler"
      ],
      "metadata": {
        "id": "UnJ4V7vtg8Hh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "X_scaler = StandardScaler(epsilon = 0.2,bounds = ([21,80,102,67,62],[86,215,597,157,222])) #Sex bounds is not included"
      ],
      "metadata": {
        "id": "cm4Nfviuhnt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "X_train_std = X_scaler.fit_transform(x_train[[\"age\",\"bp\", \"ch\", \"bs\", \"phr\"]])"
      ],
      "metadata": {
        "id": "Rc5kfDdRg8Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sex column is categoric, means that already scaled so I kept it seperated then join it with scaled dataframe\n",
        "\n",
        "%%ag\n",
        "X_train_std = X_train_std.join(x_train[['sex']])"
      ],
      "metadata": {
        "id": "MOHEa7c_g7-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ryybS0x4g77v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d7_HvlDzg7zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "X_test_std = X_scaler.transform(x_test[[\"age\",\"bp\", \"ch\", \"bs\", \"phr\"]])"
      ],
      "metadata": {
        "id": "_O36L4xeif7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "ag_print(X_test_std)"
      ],
      "metadata": {
        "id": "dJJ3f0Exg7xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transforming above return raw data without column name so I need to create new dataframe with column name\n",
        "\n",
        "%%ag\n",
        "import pandas as pd\n",
        "X_test_std = pd.DataFrame(X_test_std, columns = [\"age\",\"bp\", \"ch\", \"bs\", \"phr\"] )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PfBgA_xVhU3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "X_test_std = X_test_std.join(x_test[['sex']])"
      ],
      "metadata": {
        "id": "yKFLPiDHhVcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "\n",
        "ag_print(X_test_std)"
      ],
      "metadata": {
        "id": "x6WBWtzyhVhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i5aOsPrBhVlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qttUzrUHhVp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We can test and see what our bounds of  scaled x_test data are, so in the scenario of cretaing PrivateDataFrmae\n",
        "#we can use them as a metadata. In this note book i dont but during developing the model I use it in a couple of experiments\n",
        "\n",
        "#like this\n",
        "\"\"\"{\"age\":(-3.231322116161105,3.126608937803356),\"sex\":(0,1),\"bp\":(-2.3587053350012646,4.11330047355693),\n",
        "\"ch\":(-2.0595143397556464,5.23177028955764),\"bs\":(-1.6838249760431203,2.707904986315708),\n",
        "        \"phr\":(-5.1514514050320885,4.214822075062706)} \"\"\"\n",
        "\n",
        "%%ag\n",
        "for i in x_test.columns:\n",
        "  ag_print(i,X_test_std[i].min(),X_test_std[i].max())"
      ],
      "metadata": {
        "id": "6X-EUr22g7vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MtTxkUVRg7r7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jiikiiUKg7oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ySvoeeW0g7Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéà A quick solution\n",
        "\n",
        "In this section we evaluate an editorial solution in AG using TensorFlow!"
      ],
      "metadata": {
        "id": "KARrFlm5pOB6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0hCol4-Cf4JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### I tried to develope model a number of time with different parameter values\n",
        "## more and less the top scored model I submitsted should be this one"
      ],
      "metadata": {
        "id": "ju9swhyzf32i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lq9ySh4Jf3bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "import tensorflow as tf\n",
        "from op_pandas import standard_scaler, PrivateDataFrame\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from op_tensorflow import PrivateKerasModel, PrivateDataLoader\n",
        "\n",
        "\n",
        "# Normal keras model\n",
        "seqM = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(6,)),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "\n",
        "dp_model = PrivateKerasModel(model=seqM, l2_norm_clip=1, noise_multiplier=1)\n",
        "\n",
        "#let set lr 0.001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "\n",
        "dp_model.compile(\n",
        "\toptimizer = optimizer,\n",
        "\tloss = 'binary_crossentropy',\n",
        "\tmetrics = [\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "QVMog5sFunqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20089257-81f7-4284-d1b1-d3020fab4fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/site-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if (distutils.version.LooseVersion(tf.__version__) <\n",
            "/usr/local/lib/python3.10/site-packages/tensorflow_probability/python/__init__.py:58: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  distutils.version.LooseVersion(required_tensorflow_version)):\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "x_train_scaled = standard_scaler(x_train, eps=.1)\n",
        "x_train_scaled.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtZnkEIGu4Oy",
        "outputId": "9b65d460-abfb-47e3-b99d-2501eadfadcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+-------------+---------------+---------+------------------------------------------+\n",
            "|    | Column   | numerical   | categorical   | dtype   | bounds                                   |\n",
            "|----+----------+-------------+---------------+---------+------------------------------------------|\n",
            "|  0 | age      | True        | False         | float64 | (-3.434428441950818, 3.251320884665355)  |\n",
            "|  1 | sex      | True        | False         | float64 | (-1.5464939599176255,                    |\n",
            "|    |          |             |               |         | 0.7585069065360925)                      |\n",
            "|  2 | bp       | True        | False         | float64 | (-1.9262570222101114, 2.969333123214706) |\n",
            "|  3 | ch       | True        | False         | float64 | (-6.62666685526513, 15.939133150116538)  |\n",
            "|  4 | bs       | True        | False         | float64 | (-1.2919946241806954,                    |\n",
            "|    |          |             |               |         | 1.9166940009123714)                      |\n",
            "|  5 | phr      | True        | False         | float64 | (-4.067968385342857, 3.384620291743224)  |\n",
            "+----+----------+-------------+---------------+---------+------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "data_loader = PrivateDataLoader(feature_df=X_train_std , label_df=y_train, batch_size=32)"
      ],
      "metadata": {
        "id": "-IRE6nbYvcw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "dp_model.fit(x=data_loader, epochs=44, target_delta=1/128)"
      ],
      "metadata": {
        "id": "4liI6okplRVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "y_pred = dp_model.predict(PrivateDataFrame(X_test_std), label_columns=[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt_0vemmvq17",
        "outputId": "d2ebe4a3-01aa-4923-805c-8702feb2d7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 1/63 [..............................] - ETA: 18s\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4/63 [>.............................] - ETA: 1s \n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18/63 [=======>......................] - ETA: 0s\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/63 [===============>..............] - ETA: 0s\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r51/63 [=======================>......] - ETA: 0s\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r63/63 [==============================] - 1s 6ms/step\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9KSbYO81ga5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternative wayof creating PrivateDataFrame with metadata\n",
        "%%ag\n",
        "\n",
        "y_pred = dp_model.predict(PrivateDataFrame(X_test_std,metadata={\"age\":(-3.231322116161105,3.126608937803356),\"sex\":(0,1),\"bp\":(-2.3587053350012646,4.11330047355693),\"ch\":(-2.0595143397556464,5.23177028955764),\"bs\":(-1.6838249760431203,2.707904986315708),\"phr\":(-5.1514514050320885,4.214822075062706)}), label_columns=[\"output\"])"
      ],
      "metadata": {
        "id": "J9VSFflJgXn7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GmBDfU2IgbgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "# Note that the predictions are a float scalar\n",
        "# so we scale it\n",
        "def f(x: float) -> float:\n",
        "  if x > 0.5:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "y_pred[\"output\"] = y_pred[\"output\"].map(f, output_bounds=(0, 1))"
      ],
      "metadata": {
        "id": "mJMoynKBAwMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "result = submit_predictions(y_pred)"
      ],
      "metadata": {
        "id": "weUQGJAMgjYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H7P9jnDVgsnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bn4SiBjtgsdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KkmDb8mBgsM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VEekXGyGgr4B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}