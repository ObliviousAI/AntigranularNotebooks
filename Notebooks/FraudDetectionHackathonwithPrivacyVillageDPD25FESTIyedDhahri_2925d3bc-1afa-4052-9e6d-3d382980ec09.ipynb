{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuIGLYkl_jCM"
      },
      "outputs": [],
      "source": [
        "!pip install antigranular &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "BD3ti7Cp_jCO",
        "outputId": "85d82f35-22e4-4930-ac11-e7ccf1d576fd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset \"Transaction Fraud Hackathon Dataset\" loaded to the kernel as \u001b[92mtransaction_fraud_hackathon_dataset\u001b[0m\n",
            "Key Name                       Value Type     \n",
            "---------------------------------------------\n",
            "test_x                         DataFrame      \n",
            "train_x                        PrivateDataFrame\n",
            "train_y                        PrivateDataFrame\n",
            "\n",
            "Connected to Antigranular server session id: 2925d3bc-1afa-4052-9e6d-3d382980ec09, the session will time out if idle for 25 minutes\n",
            "Cell magic '%%ag' registered successfully, use `%%ag` in a notebook cell to execute your python code on Antigranular private python server\n",
            "ðŸš€ Everything's set up and ready to roll!\n"
          ]
        }
      ],
      "source": [
        "import antigranular as ag\n",
        "session = ag.login(<client_id>,<client_secret>, competition = \"Fraud Detection Hackathon with Privacy Village #DPD25FEST\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o93Ge1AXqkaN"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "x_train = transaction_fraud_hackathon_dataset[\"train_x\"]\n",
        "y_train = transaction_fraud_hackathon_dataset[\"train_y\"]\n",
        "x_test = transaction_fraud_hackathon_dataset[\"test_x\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heNuJZmD_jCQ",
        "outputId": "24e9ac71-f011-4787-eb05-cf7e4b1c892a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/site-packages/tensorflow/__init__.py:30: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
            "  import distutils as _distutils\n",
            "\n",
            "2025-03-03 22:48:02.922341: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-03-03 22:48:02.925536: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-03-03 22:48:03.041360: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-03-03 22:48:03.041396: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-03-03 22:48:03.042322: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-03 22:48:03.120174: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-03-03 22:48:03.122783: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "2025-03-03 22:48:06.625437: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from op_pandas import standard_scaler, PrivateDataFrame\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from op_tensorflow import PrivateKerasModel, PrivateDataLoader\n",
        "\n",
        "# Define a Sequential neural network model with multiple layers\n",
        "seqM = Sequential([\n",
        "    # First hidden layer: Wide input layer with 256 neurons\n",
        "    # Input shape of 9 features, using L2 regularization to prevent overfitting\n",
        "    Dense(256, input_shape=(9,), kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    # Batch normalization to normalize layer inputs, helping stabilize training\n",
        "    BatchNormalization(momentum=0.9),\n",
        "    # ReLU activation function to introduce non-linearity\n",
        "    tf.keras.layers.ReLU(),\n",
        "    # Dropout layer to reduce overfitting by randomly setting input units to 0\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Second hidden layer with 128 neurons\n",
        "    Dense(128, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    BatchNormalization(momentum=0.9),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Third hidden layer with 64 neurons\n",
        "    Dense(64, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    BatchNormalization(momentum=0.9),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Fourth hidden layer with 32 neurons\n",
        "    Dense(32, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    BatchNormalization(momentum=0.9),\n",
        "    tf.keras.layers.ReLU(),\n",
        "\n",
        "    # Output layer for binary classification using sigmoid activation\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Create a Differentially Private Keras Model\n",
        "# Adds privacy protection to the neural network\n",
        "dp_model = PrivateKerasModel(\n",
        "    model=seqM,\n",
        "    l2_norm_clip=1,  # Clip gradient norms to prevent excessive updates\n",
        "    noise_multiplier=1  # Add noise to gradients to protect individual data privacy\n",
        ")\n",
        "\n",
        "# Configure Adam optimizer with carefully tuned hyperparameters\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0001,  # Small learning rate for stable convergence\n",
        "    beta_1=0.9,  # Exponential decay rate for first moment estimates\n",
        "    beta_2=0.999,  # Exponential decay rate for second moment estimates\n",
        "    epsilon=1e-7,  # Small value to prevent division by zero\n",
        "    amsgrad=True  # Use AMSGrad variant to improve convergence\n",
        ")\n",
        "\n",
        "# Compile the differentially private model\n",
        "# Specifies loss function, optimizer, and evaluation metrics\n",
        "dp_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='binary_crossentropy',  # Standard loss for binary classification\n",
        "    metrics=['accuracy']  # Track model's accuracy during training\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TGm56oV_jCT"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "#Using batch size 256 for better generalization\n",
        "data_loader = PrivateDataLoader(feature_df=x_train , label_df=y_train, batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWCbDJaJiMNl"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "#I'm training the model running this several time, the best score I get I run this code 3 times\n",
        "dp_model.fit(x=data_loader, epochs=50,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjZbehXE_jCU"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "#make predictions\n",
        "test=PrivateDataFrame(x_test).copy()\n",
        "y_pred = dp_model.predict(test, label_columns=[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAqHlwnKrJGT"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "#prepare predictions, usually these datasets are umbalanced so I tried with different thresholds and the best was the default last on the public leaderbord may on the private leaderborad my best score was with another threshhold\n",
        "def f(x: float) -> float:\n",
        "    return 1 if x > 0.5 else 0\n",
        "\n",
        "y_pred[\"output\"] = y_pred[\"output\"].map(f, output_bounds=(0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1oLyAaKrMb_"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "#submit predictions\n",
        "result = submit_predictions(y_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}