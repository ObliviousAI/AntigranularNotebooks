{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pZhi_MuHbC6r"
      },
      "outputs": [],
      "source": [
        "!pip install antigranular &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Bov6Ad29bKjG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "29069477-a0af-4dd6-ef7b-edf722774353"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset \"Transaction Fraud Hackathon Dataset\" loaded to the kernel as \u001b[92mtransaction_fraud_hackathon_dataset\u001b[0m\n",
            "Key Name                       Value Type     \n",
            "---------------------------------------------\n",
            "test_x                         DataFrame      \n",
            "train_x                        PrivateDataFrame\n",
            "train_y                        PrivateDataFrame\n",
            "\n",
            "Connected to Antigranular server session id: fe45a754-18dc-4bac-98b5-24d9fac2185f, the session will time out if idle for 25 minutes\n",
            "Cell magic '%%ag' registered successfully, use `%%ag` in a notebook cell to execute your python code on Antigranular private python server\n",
            "ðŸš€ Everything's set up and ready to roll!\n"
          ]
        }
      ],
      "source": [
        "import antigranular as ag\n",
        "session = ag.login(<client_id>,<client_secret>, competition = \"Fraud Detection Hackathon with Privacy Village #DPD25FEST\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uApC_7IebOsg"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "x_train = transaction_fraud_hackathon_dataset[\"train_x\"]\n",
        "y_train = transaction_fraud_hackathon_dataset[\"train_y\"]\n",
        "x_test = transaction_fraud_hackathon_dataset[\"test_x\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JpMK-flNgfoR"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "\n",
        "#Sequential model nn with conv\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from op_tensorflow import PrivateKerasModel, PrivateDataLoader\n",
        "import op_tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv1D,Dropout,Flatten,BatchNormalization\n",
        "from op_tensorflow import PrivateKerasModel, PrivateDataLoader\n",
        "import op_pandas\n",
        "from op_pandas import standard_scaler, PrivateDataFrame, train_test_split\n",
        "\n",
        "concat_df = x_train.join(y_train)\n",
        "train_data, test_data = op_pandas.train_test_split(concat_df, test_size=0.0001, random_state=42)\n",
        "\n",
        "train_y = train_data['fraud'].copy()\n",
        "train_data.drop(columns=['fraud'], inplace=True)\n",
        "\n",
        "test_y = test_data['fraud'].copy()\n",
        "test_data.drop(columns=['fraud'], inplace=True)\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 15\n",
        "noise_multiplier = 0.3\n",
        "target_delta = 1\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(128,6, activation='relu', input_shape=(9, 1)),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(128,4, activation='relu',padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "dp_model = PrivateKerasModel(\n",
        "    model=model,\n",
        "    l2_norm_clip=1,\n",
        "    noise_multiplier=noise_multiplier\n",
        ")\n",
        "\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# Model compile\n",
        "dp_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
        "\n",
        "# Model compile\n",
        "dp_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "# Data loader\n",
        "data_loader = PrivateDataLoader(\n",
        "    feature_df=train_data,\n",
        "    label_df=train_y,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "\n",
        "dp_model.fit(\n",
        "    x=data_loader,\n",
        "    epochs=epochs,\n",
        "    target_delta=target_delta,\n",
        "    #validation_data=(test_data, test_y)\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMdnfSHugfeB"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "from op_pandas import standard_scaler, PrivateDataFrame\n",
        "test=PrivateDataFrame(x_test).copy()\n",
        "y_pred = dp_model.predict(test, label_columns=[\"output\"])\n",
        "# Note that the predictions are a float scalar\n",
        "# so we scale it\n",
        "def f(x: float) -> int:\n",
        "  if x > 0.5:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "y_pred[\"output\"] = y_pred[\"output\"].map(f, output_categories=[0, 1])\n",
        "result = submit_predictions(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7Jo6ARIr-q5"
      },
      "outputs": [],
      "source": [
        "session.privacy_odometer()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}