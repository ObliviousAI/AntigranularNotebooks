{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntAr1tjWX-LI"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLT32OQQtkwo"
      },
      "outputs": [],
      "source": [
        "# Install the Antigranular package\n",
        "!pip install antigranular &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "9HDWHfcBtvdc",
        "outputId": "f625884e-1ff6-4e77-ea17-668f59ae7511"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset \"Heart Disease Prediction Hackathon Dataset\" loaded to the kernel as \u001b[92mheart_disease_prediction_hackathon_dataset\u001b[0m\n",
            "Key Name                       Value Type     \n",
            "---------------------------------------------\n",
            "train_y                        PrivateDataFrame\n",
            "train_x                        PrivateDataFrame\n",
            "test_x                         DataFrame      \n",
            "\n",
            "Connected to Antigranular server session id: 38606523-88c4-44d3-80c1-386422337201, the session will time out if idle for 25 minutes\n",
            "Cell magic '%%ag' registered successfully, use `%%ag` in a notebook cell to execute your python code on Antigranular private python server\n",
            "ðŸš€ Everything's set up and ready to roll!\n"
          ]
        }
      ],
      "source": [
        "import antigranular as ag\n",
        "session = ag.login(<client_id>,<client_secret>, competition = \"Heart Disease Prediction Hackathon\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qv6RR1KTt75-"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "x_train = heart_disease_prediction_hackathon_dataset[\"train_x\"]\n",
        "y_train = heart_disease_prediction_hackathon_dataset[\"train_y\"]\n",
        "x_test = heart_disease_prediction_hackathon_dataset[\"test_x\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9YK9wsW4oE_",
        "outputId": "d9734229-0de0-43bb-a552-a47691aed11f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['age', 'sex', 'bp', 'ch', 'bs', 'phr']\n",
            "Index(['age', 'sex', 'bp', 'ch', 'bs', 'phr'], dtype='object')\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "ag_print(x_train.columns)\n",
        "ag_print(x_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp0-TfxfNl5T",
        "outputId": "5212afac-3340-476f-9e4a-ec003978cc6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      age  sex   bp   ch   bs  phr\n",
            "0      71    1  128  326   95  117\n",
            "1      61    1  153  270   98  123\n",
            "2      59    1  113  236  106  181\n",
            "3      69    0  109  151  109  108\n",
            "4      55    0  137  235  101  150\n",
            "...   ...  ...  ...  ...  ...  ...\n",
            "1995   60    1  128  261  112  143\n",
            "1996   50    1  143  216   94  100\n",
            "1997   64    1  120  172   87  142\n",
            "1998   56    1  158  294   82  144\n",
            "1999   69    0  117  559  112  157\n",
            "\n",
            "[2000 rows x 6 columns]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "ag_print(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Differential Privacy with TensorFlow and Custom Scaling\n",
        "\n",
        "In this notebook, we implement differential privacy in machine learning models using TensorFlow. We apply custom Min-Max scaling to preprocess the data and build a privacy-preserving neural network using TensorFlow's `PrivateKerasModel`.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-FLyF3X3HESe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Min-Max Scaler Function Definition\n",
        "This cell defines a custom function `min_max_scaler_manual` that applies Min-Max scaling to the data. The function scales each column in the DataFrame to a range of [0, 1] using the minimum and maximum values provided in the metadata."
      ],
      "metadata": {
        "id": "nkejM5NAHrsd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkmL766uJgS8"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "def min_max_scaler_manual(data, metadata):\n",
        "    # Initialize an empty dictionary to store the scaled data\n",
        "    scaled_data_dict = data\n",
        "\n",
        "    # Iterate over each column in the data\n",
        "    for col in data.columns:\n",
        "        # Extract the min and max from the metadata\n",
        "        col_min = metadata[col][0]\n",
        "        col_max = metadata[col][1]\n",
        "\n",
        "        # Scale the column data\n",
        "        scaled_data_dict[col] = (data[col] - col_min) / (col_max - col_min)\n",
        "\n",
        "    return scaled_data_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply Min-Max Scaling to Training and Test Data\n",
        "This cell applies the `min_max_scaler_manual` function to scale both the `x_train` and `x_test` datasets using the metadata from `x_train`. The scaled data is stored in `x_train_scaled` and `x_test_scaled`.\n"
      ],
      "metadata": {
        "id": "mecRYONYHJ1L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIrYAy_6NyHl"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "x_test_scaled = min_max_scaler_manual(x_test, x_train.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Caz91v7HKgf9"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "x_train_scaled = min_max_scaler_manual(x_train, x_train.metadata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYtK367FO2wB",
        "outputId": "f96e4c63-a95a-4e94-9661-0041d14e9818"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           age  sex        bp        ch        bs      phr\n",
            "0     0.769231  1.0  0.355556  0.452525  0.311111  0.34375\n",
            "1     0.615385  1.0  0.540741  0.339394  0.344444  0.38125\n",
            "2     0.584615  1.0  0.244444  0.270707  0.433333  0.74375\n",
            "3     0.738462  0.0  0.214815  0.098990  0.466667  0.28750\n",
            "4     0.523077  0.0  0.422222  0.268687  0.377778  0.55000\n",
            "...        ...  ...       ...       ...       ...      ...\n",
            "1995  0.600000  1.0  0.355556  0.321212  0.500000  0.50625\n",
            "1996  0.446154  1.0  0.466667  0.230303  0.300000  0.23750\n",
            "1997  0.661538  1.0  0.296296  0.141414  0.222222  0.50000\n",
            "1998  0.538462  1.0  0.577778  0.387879  0.166667  0.51250\n",
            "1999  0.738462  0.0  0.274074  0.923232  0.500000  0.59375\n",
            "\n",
            "[2000 rows x 6 columns]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "ag_print(x_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmweAgqsSXw-",
        "outputId": "d261ee91-fa12-46bd-c4a5-34f9969e37d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'age': (21, 86), 'sex': (0, 1), 'bp': (80, 215), 'ch': (102, 597), 'bs': (67, 157), 'phr': (62, 222)}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "ag_print(x_train.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIKASfNNSqHo",
        "outputId": "bc4d8477-664d-40f7-b640-dfd985e55e30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      age  sex   bp   ch   bs  phr\n",
            "0      71    1  128  326   95  117\n",
            "1      61    1  153  270   98  123\n",
            "2      59    1  113  236  106  181\n",
            "3      69    0  109  151  109  108\n",
            "4      55    0  137  235  101  150\n",
            "...   ...  ...  ...  ...  ...  ...\n",
            "1995   60    1  128  261  112  143\n",
            "1996   50    1  143  216   94  100\n",
            "1997   64    1  120  172   87  142\n",
            "1998   56    1  158  294   82  144\n",
            "1999   69    0  117  559  112  157\n",
            "\n",
            "[2000 rows x 6 columns]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "ag_print(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and Compile Differentially Private Neural Network Model\n",
        "\n",
        "This cell imports necessary libraries for building a TensorFlow model with differential privacy. Specifically:\n",
        "\n",
        "1. **Import Libraries**:\n",
        "   - `tensorflow` is imported for building and training the neural network.\n",
        "   - `standard_scaler` and `PrivateDataFrame` from `op_pandas` are used for data preprocessing and handling private data.\n",
        "   - `Sequential`, `Dense`, `Dropout`, and `BatchNormalization` from `tensorflow.keras` are used to construct the neural network model.\n",
        "   - `PrivateKerasModel` and `PrivateDataLoader` from `op_tensorflow` are used to apply differential privacy to the model.\n",
        "\n",
        "2. **Model Architecture**:\n",
        "   - A `Sequential` model is created with several `Dense` layers, which are fully connected layers in the neural network.\n",
        "   - Each `Dense` layer is followed by `BatchNormalization` and `Dropout` layers:\n",
        "     - **`Dense` Layers**: These layers apply linear transformations followed by activation functions (`relu` for hidden layers and `sigmoid` for the output layer) to introduce non-linearity into the model.\n",
        "     - **`BatchNormalization` Layers**: These normalize the output of the previous layer to improve training stability and speed.\n",
        "     - **`Dropout` Layers**: These randomly drop units during training to prevent overfitting by making the model more robust.\n",
        "\n",
        "3. **Create Differentially Private Model**:\n",
        "   - `PrivateKerasModel` is used to create a differentially private version of the neural network. It includes:\n",
        "     - `l2_norm_clip=1`: Limits the L2 norm of the gradients to control the impact of individual data points.\n",
        "     - `noise_multiplier=1000`: Adds noise to the gradients to enhance privacy. A higher value provides stronger privacy protection but may affect model performance.\n",
        "\n",
        "4. **Compile the Model**:\n",
        "   - The model is compiled using the Adam optimizer with a learning rate of `0.01` and the binary cross-entropy loss function.\n",
        "   - **Optimizer**: The Adam optimizer is used for adjusting the weights of the model based on the gradients.\n",
        "   - **Loss Function**: Binary cross-entropy is used since this is a binary classification problem.\n",
        "   - **Metrics**: Accuracy is used to evaluate the model's performance during training and validation.\n",
        "\n",
        "In summary, this cell sets up a differentially private neural network model with TensorFlow, including defining the model architecture, applying differential privacy, and compiling the model for training.\n"
      ],
      "metadata": {
        "id": "w1FUchezI9WR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWBB_OILQxmX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_ovM5TeAlNP"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "import tensorflow as tf\n",
        "from op_pandas import standard_scaler, PrivateDataFrame\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from op_tensorflow import PrivateKerasModel, PrivateDataLoader\n",
        "\n",
        "\n",
        "seqM1 = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(6,)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "# Create DP keras model\n",
        "dp_model1 = PrivateKerasModel(model=seqM1, l2_norm_clip=1, noise_multiplier=1000)\n",
        "\n",
        "# Use a standard (non-DP) optimizer directly from keras.\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "# PrivateKerasModel uses similar API as standard Keras\n",
        "dp_model1.compile(\n",
        "\toptimizer = optimizer,\n",
        "\tloss = 'binary_crossentropy',\n",
        "\tmetrics = [\"accuracy\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reason for Using a High Noise Multiplier**\n",
        "\n",
        "I used a high noise multiplier of `1000` to ensure strong privacy guarantees. Since I was trying to use smaller epsilon for better privacy, the large noise multiplier compensates for this by adding sufficient noise to protect individual data points. Although this can reduce model performance, it helps prevent overfitting by acting as a form of regularization. The goal was to balance strong privacy with acceptable model accuracy.\n"
      ],
      "metadata": {
        "id": "V7xAV1PLIjEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare DataLoader for Training\n",
        "This cell creates a `PrivateDataLoader` to handle private data, specifying the training data and batch size. This loader is used to provide data to the model during training while preserving privacy.\n"
      ],
      "metadata": {
        "id": "SWoWeX-lHWPL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUSCGHnpAy6M"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "# Assuming you have preprocessed and scaled your data into x_train_scaled, y_train, x_test_scaled, y_test\n",
        "data_loader = PrivateDataLoader(feature_df=x_train_scaled, label_df=y_train, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manage Privacy Budget\n",
        "This cell uses the `get_privacy_budget` function to calculate the privacy budget for the training process based on the sample size, batch size, number of epochs, noise multiplier, and target delta."
      ],
      "metadata": {
        "id": "5aTX-JmrHZuK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyHWVjvdMNDw",
        "outputId": "107e282b-7543-4150-857d-e64f53ea3b0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> EPSILON_REQUIRED = 0.0075974776466098395 using TARGET_DELTA = 1e-05\n",
            "Training parameters used :-\n",
            "    SAMPLE_SIZE = 2000\n",
            "    BATCH_SIZE = 32\n",
            "    NUM_EPOCHS = 500\n",
            "    NOISE_MULTIPLIER = 1000\n",
            "    \n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "from op_tensorflow import get_privacy_budget\n",
        "get_privacy_budget(\n",
        "    sample_size=2000,\n",
        "    batch_size=32,\n",
        "    num_epochs=500,\n",
        "    noise_multiplier=1000,\n",
        "    target_delta=1e-5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the Differentially Private Model\n",
        "This cell fits the differentially private model (`dp_model1`) to the scaled training data (`x_train_scaled`, `y_train`) for a specified number of epochs and batch size.\n"
      ],
      "metadata": {
        "id": "cG8eevzWHct2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJoVJ4ixA3TH",
        "outputId": "d6307907-bd52-4a0b-fd16-6408fa27cfb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "250/250 - 17s - loss: 0.5745 - accuracy: 0.7028 - 17s/epoch - 69ms/step\n",
            "\n",
            "Epoch 2/100\n",
            "\n",
            "250/250 - 8s - loss: 0.5491 - accuracy: 0.7172 - 8s/epoch - 34ms/step\n",
            "\n",
            "Epoch 3/100\n",
            "\n",
            "250/250 - 8s - loss: 0.5149 - accuracy: 0.7417 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 4/100\n",
            "\n",
            "250/250 - 8s - loss: 0.5144 - accuracy: 0.7309 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 5/100\n",
            "\n",
            "250/250 - 8s - loss: 0.5110 - accuracy: 0.7347 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 6/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4994 - accuracy: 0.7452 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 7/100\n",
            "\n",
            "250/250 - 8s - loss: 0.5088 - accuracy: 0.7413 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 8/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4911 - accuracy: 0.7523 - 8s/epoch - 34ms/step\n",
            "\n",
            "Epoch 9/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4998 - accuracy: 0.7493 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 10/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4941 - accuracy: 0.7549 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 11/100\n",
            "\n",
            "250/250 - 8s - loss: 0.5007 - accuracy: 0.7439 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 12/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4842 - accuracy: 0.7558 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 13/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4810 - accuracy: 0.7612 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 14/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4751 - accuracy: 0.7700 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 15/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4881 - accuracy: 0.7638 - 8s/epoch - 34ms/step\n",
            "\n",
            "Epoch 16/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4732 - accuracy: 0.7726 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 17/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4674 - accuracy: 0.7715 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 18/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4729 - accuracy: 0.7747 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 19/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4668 - accuracy: 0.7748 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 20/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4654 - accuracy: 0.7719 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 21/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4791 - accuracy: 0.7678 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 22/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4620 - accuracy: 0.7752 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 23/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4550 - accuracy: 0.7768 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 24/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4687 - accuracy: 0.7725 - 8s/epoch - 34ms/step\n",
            "\n",
            "Epoch 25/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4581 - accuracy: 0.7796 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 26/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4481 - accuracy: 0.7864 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 27/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4519 - accuracy: 0.7860 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 28/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4508 - accuracy: 0.7866 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 29/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4501 - accuracy: 0.7849 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 30/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4563 - accuracy: 0.7785 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 31/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4444 - accuracy: 0.7900 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 32/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4385 - accuracy: 0.7894 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 33/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4508 - accuracy: 0.7885 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 34/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4424 - accuracy: 0.7922 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 35/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4569 - accuracy: 0.7872 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 36/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4423 - accuracy: 0.7923 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 37/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4374 - accuracy: 0.8003 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 38/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4410 - accuracy: 0.7877 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 39/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4319 - accuracy: 0.8001 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 40/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4305 - accuracy: 0.7961 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 41/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4247 - accuracy: 0.8013 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 42/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4398 - accuracy: 0.7913 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 43/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4249 - accuracy: 0.7963 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 44/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4310 - accuracy: 0.7952 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 45/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4341 - accuracy: 0.7937 - 8s/epoch - 34ms/step\n",
            "\n",
            "Epoch 46/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4320 - accuracy: 0.7948 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 47/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4326 - accuracy: 0.7931 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 48/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4342 - accuracy: 0.7924 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 49/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4263 - accuracy: 0.8022 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 50/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4237 - accuracy: 0.8027 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 51/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4280 - accuracy: 0.7962 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 52/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4296 - accuracy: 0.7958 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 53/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4332 - accuracy: 0.7939 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 54/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4207 - accuracy: 0.8048 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 55/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4260 - accuracy: 0.8024 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 56/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4241 - accuracy: 0.8051 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 57/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4169 - accuracy: 0.8040 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 58/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4086 - accuracy: 0.8141 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 59/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4106 - accuracy: 0.8084 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 60/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4260 - accuracy: 0.8032 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 61/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4187 - accuracy: 0.8050 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 62/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4063 - accuracy: 0.8133 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 63/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4073 - accuracy: 0.8096 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 64/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4060 - accuracy: 0.8147 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 65/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4132 - accuracy: 0.8090 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 66/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4151 - accuracy: 0.8044 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 67/100\n",
            "\n",
            "250/250 - 9s - loss: 0.4037 - accuracy: 0.8119 - 9s/epoch - 34ms/step\n",
            "\n",
            "Epoch 68/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3967 - accuracy: 0.8191 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 69/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4040 - accuracy: 0.8142 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 70/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4008 - accuracy: 0.8136 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 71/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4118 - accuracy: 0.8110 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 72/100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "# Fit the model with validation split\n",
        "dp_model1.fit(\n",
        "    x=x_train_scaled,\n",
        "    y=y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pAwFk5_csrp",
        "outputId": "6487501f-46b1-40ae-a3d9-79e63961f09d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4155 - accuracy: 0.8066 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 2/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4122 - accuracy: 0.8071 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 3/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4154 - accuracy: 0.8020 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 4/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4054 - accuracy: 0.8097 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 5/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3994 - accuracy: 0.8165 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 6/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4082 - accuracy: 0.8088 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 7/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4065 - accuracy: 0.8069 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 8/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4009 - accuracy: 0.8168 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 9/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4111 - accuracy: 0.8113 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 10/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3929 - accuracy: 0.8223 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 11/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4042 - accuracy: 0.8148 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 12/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3941 - accuracy: 0.8166 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 13/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4126 - accuracy: 0.8126 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 14/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4077 - accuracy: 0.8130 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 15/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4073 - accuracy: 0.8102 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 16/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4059 - accuracy: 0.8123 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 17/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4035 - accuracy: 0.8136 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 18/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3919 - accuracy: 0.8207 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 19/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3891 - accuracy: 0.8220 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 20/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3958 - accuracy: 0.8210 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 21/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3905 - accuracy: 0.8217 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 22/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3973 - accuracy: 0.8185 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 23/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3878 - accuracy: 0.8240 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 24/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4078 - accuracy: 0.8099 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 25/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3963 - accuracy: 0.8170 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 26/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4011 - accuracy: 0.8098 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 27/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3872 - accuracy: 0.8233 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 28/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4021 - accuracy: 0.8094 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 29/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4012 - accuracy: 0.8137 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 30/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3859 - accuracy: 0.8260 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 31/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3886 - accuracy: 0.8211 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 32/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3921 - accuracy: 0.8218 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 33/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3932 - accuracy: 0.8162 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 34/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3949 - accuracy: 0.8195 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 35/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3942 - accuracy: 0.8182 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 36/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3923 - accuracy: 0.8168 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 37/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3951 - accuracy: 0.8154 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 38/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3824 - accuracy: 0.8211 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 39/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4110 - accuracy: 0.8108 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 40/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3943 - accuracy: 0.8140 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 41/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3966 - accuracy: 0.8168 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 42/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3856 - accuracy: 0.8265 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 43/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3947 - accuracy: 0.8201 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 44/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3913 - accuracy: 0.8195 - 8s/epoch - 34ms/step\n",
            "\n",
            "Epoch 45/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3929 - accuracy: 0.8172 - 8s/epoch - 34ms/step\n",
            "\n",
            "Epoch 46/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4004 - accuracy: 0.8145 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 47/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3861 - accuracy: 0.8205 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 48/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3918 - accuracy: 0.8235 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 49/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3822 - accuracy: 0.8226 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 50/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3853 - accuracy: 0.8244 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 51/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3841 - accuracy: 0.8230 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 52/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4020 - accuracy: 0.8069 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 53/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3899 - accuracy: 0.8197 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 54/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3868 - accuracy: 0.8224 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 55/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3850 - accuracy: 0.8239 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 56/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3891 - accuracy: 0.8180 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 57/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3804 - accuracy: 0.8279 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 58/100\n",
            "\n",
            "250/250 - 8s - loss: 0.4037 - accuracy: 0.8205 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 59/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3921 - accuracy: 0.8176 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 60/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3762 - accuracy: 0.8347 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 61/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3955 - accuracy: 0.8189 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 62/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3889 - accuracy: 0.8215 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 63/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3874 - accuracy: 0.8196 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 64/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3743 - accuracy: 0.8255 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 65/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3902 - accuracy: 0.8182 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 66/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3744 - accuracy: 0.8279 - 8s/epoch - 34ms/step\n",
            "\n",
            "Epoch 67/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3951 - accuracy: 0.8157 - 8s/epoch - 34ms/step\n",
            "\n",
            "Epoch 68/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3916 - accuracy: 0.8149 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 69/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3804 - accuracy: 0.8251 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 70/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3814 - accuracy: 0.8267 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 71/100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "# Fit the model with validation split\n",
        "dp_model1.fit(\n",
        "    x=x_train_scaled,\n",
        "    y=y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjmVjPORfZIQ",
        "outputId": "afe2fcec-ec5a-44ad-b4cd-861630d8383b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3761 - accuracy: 0.8267 - 8s/epoch - 34ms/step\n",
            "\n",
            "Epoch 2/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3840 - accuracy: 0.8211 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 3/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3833 - accuracy: 0.8242 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 4/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3795 - accuracy: 0.8299 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 5/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3756 - accuracy: 0.8259 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 6/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3743 - accuracy: 0.8306 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 7/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3683 - accuracy: 0.8310 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 8/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3755 - accuracy: 0.8308 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 9/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3853 - accuracy: 0.8196 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 10/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3905 - accuracy: 0.8152 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 11/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3875 - accuracy: 0.8252 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 12/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3875 - accuracy: 0.8235 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 13/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3851 - accuracy: 0.8223 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 14/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3723 - accuracy: 0.8335 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 15/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3749 - accuracy: 0.8323 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 16/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3852 - accuracy: 0.8203 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 17/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3812 - accuracy: 0.8228 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 18/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3747 - accuracy: 0.8284 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 19/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3723 - accuracy: 0.8308 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 20/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3732 - accuracy: 0.8323 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 21/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3859 - accuracy: 0.8214 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 22/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3730 - accuracy: 0.8280 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 23/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3651 - accuracy: 0.8278 - 8s/epoch - 34ms/step\n",
            "\n",
            "Epoch 24/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3760 - accuracy: 0.8289 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 25/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3688 - accuracy: 0.8305 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 26/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3750 - accuracy: 0.8306 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 27/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3626 - accuracy: 0.8340 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 28/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3787 - accuracy: 0.8246 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 29/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3696 - accuracy: 0.8293 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 30/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3794 - accuracy: 0.8223 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 31/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3849 - accuracy: 0.8233 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 32/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3714 - accuracy: 0.8285 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 33/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3710 - accuracy: 0.8278 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 34/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3764 - accuracy: 0.8254 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 35/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3786 - accuracy: 0.8286 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 36/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3685 - accuracy: 0.8307 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 37/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3851 - accuracy: 0.8228 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 38/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3783 - accuracy: 0.8233 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 39/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3750 - accuracy: 0.8309 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 40/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3816 - accuracy: 0.8273 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 41/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3594 - accuracy: 0.8312 - 8s/epoch - 34ms/step\n",
            "\n",
            "Epoch 42/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3672 - accuracy: 0.8323 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 43/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3617 - accuracy: 0.8348 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 44/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3659 - accuracy: 0.8353 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 45/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3762 - accuracy: 0.8311 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 46/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3704 - accuracy: 0.8302 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 47/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3732 - accuracy: 0.8301 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 48/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3719 - accuracy: 0.8260 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 49/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3708 - accuracy: 0.8303 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 50/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3605 - accuracy: 0.8358 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 51/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3672 - accuracy: 0.8350 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 52/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3710 - accuracy: 0.8301 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 53/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3836 - accuracy: 0.8216 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 54/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3721 - accuracy: 0.8317 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 55/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3785 - accuracy: 0.8284 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 56/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3692 - accuracy: 0.8324 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 57/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3718 - accuracy: 0.8294 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 58/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3747 - accuracy: 0.8303 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 59/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3685 - accuracy: 0.8298 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 60/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3584 - accuracy: 0.8357 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 61/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3682 - accuracy: 0.8317 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 62/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3545 - accuracy: 0.8347 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 63/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3571 - accuracy: 0.8392 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 64/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3646 - accuracy: 0.8338 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 65/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3633 - accuracy: 0.8330 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 66/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3754 - accuracy: 0.8275 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 67/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3594 - accuracy: 0.8392 - 8s/epoch - 34ms/step\n",
            "\n",
            "Epoch 68/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3581 - accuracy: 0.8381 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 69/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3635 - accuracy: 0.8364 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 70/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3720 - accuracy: 0.8276 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 71/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3585 - accuracy: 0.8372 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 72/100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "# Fit the model with validation split\n",
        "dp_model1.fit(\n",
        "    x=x_train_scaled,\n",
        "    y=y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkJyMHTDiCsH",
        "outputId": "7c426fb0-1f21-4023-9848-cf11c8b69427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3667 - accuracy: 0.8324 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 2/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3508 - accuracy: 0.8415 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 3/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3693 - accuracy: 0.8338 - 8s/epoch - 34ms/step\n",
            "\n",
            "Epoch 4/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3591 - accuracy: 0.8364 - 8s/epoch - 34ms/step\n",
            "\n",
            "Epoch 5/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3550 - accuracy: 0.8368 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 6/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3522 - accuracy: 0.8379 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 7/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3621 - accuracy: 0.8366 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 8/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3694 - accuracy: 0.8341 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 9/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3527 - accuracy: 0.8392 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 10/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3628 - accuracy: 0.8341 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 11/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3551 - accuracy: 0.8389 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 12/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3579 - accuracy: 0.8375 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 13/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3715 - accuracy: 0.8281 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 14/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3673 - accuracy: 0.8314 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 15/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3514 - accuracy: 0.8424 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 16/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3493 - accuracy: 0.8426 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 17/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3547 - accuracy: 0.8380 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 18/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3547 - accuracy: 0.8423 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 19/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3520 - accuracy: 0.8439 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 20/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3671 - accuracy: 0.8349 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 21/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3631 - accuracy: 0.8274 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 22/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3578 - accuracy: 0.8406 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 23/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3613 - accuracy: 0.8337 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 24/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3476 - accuracy: 0.8409 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 25/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3622 - accuracy: 0.8330 - 8s/epoch - 34ms/step\n",
            "\n",
            "Epoch 26/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3534 - accuracy: 0.8397 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 27/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3700 - accuracy: 0.8319 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 28/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3643 - accuracy: 0.8324 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 29/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3562 - accuracy: 0.8352 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 30/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3614 - accuracy: 0.8354 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 31/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3467 - accuracy: 0.8472 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 32/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3561 - accuracy: 0.8374 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 33/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3612 - accuracy: 0.8382 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 34/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3686 - accuracy: 0.8329 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 35/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3475 - accuracy: 0.8456 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 36/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3545 - accuracy: 0.8411 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 37/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3595 - accuracy: 0.8384 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 38/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3416 - accuracy: 0.8425 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 39/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3494 - accuracy: 0.8374 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 40/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3379 - accuracy: 0.8478 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 41/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3643 - accuracy: 0.8340 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 42/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3557 - accuracy: 0.8409 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 43/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3467 - accuracy: 0.8431 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 44/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3574 - accuracy: 0.8346 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 45/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3584 - accuracy: 0.8389 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 46/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3549 - accuracy: 0.8339 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 47/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3676 - accuracy: 0.8361 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 48/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3574 - accuracy: 0.8407 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 49/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3697 - accuracy: 0.8295 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 50/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3442 - accuracy: 0.8454 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 51/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3542 - accuracy: 0.8382 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 52/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3404 - accuracy: 0.8512 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 53/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3558 - accuracy: 0.8397 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 54/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3618 - accuracy: 0.8322 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 55/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3393 - accuracy: 0.8471 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 56/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3590 - accuracy: 0.8390 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 57/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3576 - accuracy: 0.8373 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 58/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3590 - accuracy: 0.8376 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 59/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3449 - accuracy: 0.8441 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 60/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3387 - accuracy: 0.8452 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 61/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3428 - accuracy: 0.8470 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 62/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3592 - accuracy: 0.8384 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 63/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3394 - accuracy: 0.8501 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 64/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3490 - accuracy: 0.8405 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 65/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3333 - accuracy: 0.8486 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 66/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3437 - accuracy: 0.8468 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 67/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3557 - accuracy: 0.8410 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 68/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3404 - accuracy: 0.8462 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 69/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3420 - accuracy: 0.8426 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 70/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3582 - accuracy: 0.8416 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 71/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3513 - accuracy: 0.8396 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 72/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3551 - accuracy: 0.8415 - 8s/epoch - 32ms/step\n",
            "\n",
            "Epoch 73/100\n",
            "\n",
            "250/250 - 8s - loss: 0.3428 - accuracy: 0.8462 - 8s/epoch - 33ms/step\n",
            "\n",
            "Epoch 74/100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "# Fit the model with validation split\n",
        "dp_model1.fit(\n",
        "    x=x_train_scaled,\n",
        "    y=y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dsr_sNXnmegF",
        "outputId": "ca83c40f-8f81-4add-f22f-40060a9de87f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['age', 'sex', 'bp', 'ch', 'bs', 'phr']\n",
            "Index(['age', 'sex', 'bp', 'ch', 'bs', 'phr'], dtype='object')\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "ag_print(x_train_scaled.columns)\n",
        "ag_print(x_test.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict and Post-process Predictions\n",
        "This cell uses the trained model to make predictions on the scaled test data (`x_test_scaled`). The predictions are converted from float scalars to binary class labels (0 or 1) based on a threshold of 0.5."
      ],
      "metadata": {
        "id": "JchovE5XHhwQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJHVSh5UA-Ji",
        "outputId": "9beccdec-e143-46c6-8669-96a2e04efeda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r 1/63 [..............................] - ETA: 5s\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8/63 [==>...........................] - ETA: 0s\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/63 [========>.....................] - ETA: 0s\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/63 [==============>...............] - ETA: 0s\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44/63 [===================>..........] - ETA: 0s\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60/63 [===========================>..] - ETA: 0s\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r63/63 [==============================] - 1s 8ms/step\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "y_pred1 = dp_model1.predict(PrivateDataFrame(x_test_scaled), label_columns=[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2VyAu0wvD-1",
        "outputId": "216c30a5-69cc-42a5-e45a-7156d83b3bd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An exception occurred: Please ensure ag_print function is called on a non-private type.\n",
            "\n",
            "\u001b[0;31mValueError\u001b[0m: Please ensure ag_print function is called on a non-private type.\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "ag_print(y_pred1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2EOtBJ-BMfn"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "# Note that the predictions are a float scalar\n",
        "# so we scale it\n",
        "def f(x: float) -> float:\n",
        "  if x > 0.5:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "y_pred1[\"output\"] = y_pred1[\"output\"].map(f, output_bounds=(0, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdnxpI9Gb-8d",
        "outputId": "98471baa-6126-42fa-90dc-74d57d0d4cd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           age  sex        bp        ch        bs      phr\n",
            "0     0.769231  1.0  0.355556  0.452525  0.311111  0.34375\n",
            "1     0.615385  1.0  0.540741  0.339394  0.344444  0.38125\n",
            "2     0.584615  1.0  0.244444  0.270707  0.433333  0.74375\n",
            "3     0.738462  0.0  0.214815  0.098990  0.466667  0.28750\n",
            "4     0.523077  0.0  0.422222  0.268687  0.377778  0.55000\n",
            "...        ...  ...       ...       ...       ...      ...\n",
            "1995  0.600000  1.0  0.355556  0.321212  0.500000  0.50625\n",
            "1996  0.446154  1.0  0.466667  0.230303  0.300000  0.23750\n",
            "1997  0.661538  1.0  0.296296  0.141414  0.222222  0.50000\n",
            "1998  0.538462  1.0  0.577778  0.387879  0.166667  0.51250\n",
            "1999  0.738462  0.0  0.274074  0.923232  0.500000  0.59375\n",
            "\n",
            "[2000 rows x 6 columns]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "ag_print(x_test_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submit Predictions\n",
        "This cell submits the processed predictions (`y_pred1`) to the competition leaderboard.\n"
      ],
      "metadata": {
        "id": "eea8O-7BHoiW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLSehAyXB9Px",
        "outputId": "d0b252ab-3b67-4d28-f7ed-e1a4225c5639"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score: {'leaderboard': 0.9564211271444968, 'logs': {'BIN_ACC': 0.9762324159219367, 'LIN_EPS': -0.019811288777439824}}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "result = submit_predictions(y_pred1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}