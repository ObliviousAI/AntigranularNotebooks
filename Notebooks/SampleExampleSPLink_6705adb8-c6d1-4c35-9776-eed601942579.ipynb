{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Example: SPLink"
      ],
      "metadata": {
        "id": "U_mWBHwQymLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We provide two libraries for record linking, RecordLinkage and SPLink. Follow the RecordLinkage notebook [here](https://www.antigranular.com/notebooks/651a938d0f1e51b4fa0b651a)."
      ],
      "metadata": {
        "id": "GnZB8JliVADH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SPLink is a Python package designed for probabilistic record linkage, and like Record Linkage, plays a crucial part in linking records and deduplicating datasets.\n",
        "\n",
        "Participants can use SPLink to predict which rows link together and then further cluster these connections to generate an Individual ID. This can prove especially useful when unique identifiers are missing or differ significantly across datasets.\n"
      ],
      "metadata": {
        "id": "-CgLEIhZy5s7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started: Setting Up the Environment"
      ],
      "metadata": {
        "id": "Rmlact2Yyziv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install antigranular"
      ],
      "metadata": {
        "id": "GPnrlAizqLgV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "AvBsXFYHpV8f",
        "outputId": "fd4d5a35-8893-4b7b-be3a-a905e6bd13c5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset \"Flight Company Dataset for Sandbox\" to the kernel...\n",
            "Dataset \"Flight Company Dataset for Sandbox\" loaded to the kernel as flight_company_dataset_for_sandbox\n",
            "Loading dataset \"Health Organisation Dataset for Sandbox\" to the kernel...\n",
            "Dataset \"Health Organisation Dataset for Sandbox\" loaded to the kernel as health_organisation_dataset_for_sandbox\n",
            "Connected to Antigranular server session id: 6705adb8-c6d1-4c35-9776-eed601942579, the session will time out if idle for 60 minutes\n",
            "Cell magic '%%ag' registered successfully, use `%%ag` in a notebook cell to execute your python code on Antigranular private python server\n",
            "ðŸš€ Everything's set up and ready to roll!\n"
          ]
        }
      ],
      "source": [
        "import antigranular as ag\n",
        "session = ag.login(<client_id>,<client_secret>, competition = \"Sandbox for Harvard Open DP Hackathon\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the Datasets"
      ],
      "metadata": {
        "id": "TxG_yEJ_y3RO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***In this competition we are provided with two datasets:***\n",
        "\n",
        "The airline companies have information about passengers and their travel dates (`flight_company_dataset_for_sandbox`), and the national health organisation has records of patients who did the COVID test and whether their result was positive or negative (`health_organisation_dataset_for_sandbox`).\n",
        "\n",
        "These are already provided within the AG environment."
      ],
      "metadata": {
        "id": "DQaU004bzjHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "health = health_organisation_dataset_for_sandbox\n",
        "flight = flight_company_dataset_for_sandbox"
      ],
      "metadata": {
        "id": "bnKr4clsqNUY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre Processing the Data"
      ],
      "metadata": {
        "id": "Bn7zAPjC1apL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "import numpy as np\n",
        "import op_pandas as opd\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "GBBnrWrrquvt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Splink requires that you clean your data and assign unique IDs to rows before linking**\n",
        "\n",
        "* **Unique IDs:** Each input dataset must have a unique ID column, which is unique within the dataset. By default, Splink assumes this column will be called unique_id.\n",
        "* **Conformant input datasets:** Input datasets must be conformant, meaning they share the same column names and data formats.\n",
        "* **Cleaning:** Ensure data consistency by cleaning your data. This process includes standardising date formats, matching text case, and handling invalid data.\n"
      ],
      "metadata": {
        "id": "IexNGwnQ1lpG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Unique IDs"
      ],
      "metadata": {
        "id": "ynvahsPb2qpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the number of records in both the datasets is public information, we can use these to create the `unique_id` columns.\n",
        "\n",
        "For this, we use `numpy.arange`, which generates evenly spaced values within a given interval."
      ],
      "metadata": {
        "id": "RQodZo-y2tHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "num_health = 59230 #taken from competition page\n",
        "num_flight = 39028 # taken from competition page\n",
        "\n",
        "unique_id_health = opd.PrivateSeries(pd.Series(np.arange(num_health)))\n",
        "unique_id_flight = opd.PrivateSeries(pd.Series(np.arange(num_flight)))"
      ],
      "metadata": {
        "id": "E0mosknM1jxC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "health['unique_id'] = unique_id_health\n",
        "flight['unique_id'] = unique_id_flight"
      ],
      "metadata": {
        "id": "cjgtY6r1quyh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conforming Input Datasets"
      ],
      "metadata": {
        "id": "wglSKxXh38jU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to conform the various column names, let us examine what they are."
      ],
      "metadata": {
        "id": "XQ-47A-A3Ozd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "ag_print(\"Health Columns:\")\n",
        "ag_print(health.columns)\n",
        "ag_print(\"Flight Columns:\")\n",
        "ag_print(flight.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l09nS8BPqu1d",
        "outputId": "bca28a1e-06c1-4dc0-f5f1-362cdef2b89d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health Columns:\n",
            "Index(['patient_firstname', 'patient_lastname', 'patient_date_of_birth',\n",
            "       'covidtest_date', 'covidtest_result', 'patient_address', 'unique_id'],\n",
            "      dtype='object')\n",
            "Flight Columns:\n",
            "Index(['flight_number', 'flight_date', 'flight_from', 'flight_to',\n",
            "       'passenger_firstname', 'passenger_lastname', 'passenger_date_of_birth',\n",
            "       'unique_id'],\n",
            "      dtype='object')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the column names are not the same in both of the datasets. For example, first name in the health dataset is `patient_firstname` and in the flight dataset it is `passenger_firstname`.\n",
        "\n",
        "We also want to link on basis of dates (`covidtest_date` in Health Dataset and `flight_date` in Flight Dataset).\n",
        "\n",
        "Hence, we will write a function which makes the same columns of the same name."
      ],
      "metadata": {
        "id": "xWXDqbh-4Kkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "def conform_columns(df: opd.PrivateDataFrame) -> opd.PrivateDataFrame:\n",
        "    final_columns = []\n",
        "    for col in df.columns:\n",
        "        if \"firstname\" in col:  # converting patient_firstname and passenger_firstname -> firstname\n",
        "            final_columns.append(\"firstname\")\n",
        "            df[\"firstname\"] = df[col]\n",
        "        elif \"lastname\" in col:  # converting patient_lastname and passenger_lastname -> lastname\n",
        "            final_columns.append(\"lastname\")\n",
        "            df[\"lastname\"] = df[col]\n",
        "        elif \"date_of_birth\" in col: # converting patient_date_of_birth and ppassenger_date_of_birth -> date_of_birth\n",
        "            final_columns.append(\"date_of_birth\")\n",
        "            df[\"date_of_birth\"] = df[col]\n",
        "        elif \"covidtest_date\" in col: # converting covidtest_date and flight_date -> date\n",
        "            final_columns.append(\"date\")\n",
        "            df[\"date\"] = df[col]\n",
        "        elif \"flight_date\" in col:\n",
        "            final_columns.append(\"date\")\n",
        "            df[\"date\"] = df[col]\n",
        "        else:\n",
        "            final_columns.append(col)\n",
        "\n",
        "    df = df[final_columns]\n",
        "    return df\n",
        "\n",
        "health = conform_columns(health)\n",
        "flight = conform_columns(flight)"
      ],
      "metadata": {
        "id": "KBURNDVUqu4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We only need the records where covidtest_result is positive, so we will extract them."
      ],
      "metadata": {
        "id": "-RDk-5mpKjtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "# Lets remove those passenger records who tested negative.\n",
        "health['covidtest_result'] = health['covidtest_result'].where(health['covidtest_result'] == 'positive')\n",
        "health = health.dropna()"
      ],
      "metadata": {
        "id": "2wOp6sR2qu7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking out the columns again, we can see that they are conformant."
      ],
      "metadata": {
        "id": "5gEPFgkFK-lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "ag_print(\"Health Columns:\")\n",
        "ag_print(health.columns)\n",
        "ag_print(\"Flight Columns:\")\n",
        "ag_print(flight.columns)"
      ],
      "metadata": {
        "id": "UpV31l3Cqu91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "243e4221-9ad3-4ac3-cb35-3128a9e5828b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health Columns:\n",
            "Index(['firstname', 'lastname', 'date_of_birth', 'date', 'covidtest_result',\n",
            "       'patient_address', 'unique_id'],\n",
            "      dtype='object')\n",
            "Flight Columns:\n",
            "Index(['flight_number', 'date', 'flight_from', 'flight_to', 'firstname',\n",
            "       'lastname', 'date_of_birth', 'unique_id'],\n",
            "      dtype='object')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can see that the column name is conformant. But there are some columns which we don't need for our analysis, so let us remove those."
      ],
      "metadata": {
        "id": "_p0YOzTgKtIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "health_link = health[['firstname', 'lastname', 'date_of_birth', 'date', 'unique_id']]\n",
        "flight_link = flight[['firstname', 'lastname', 'date_of_birth', 'date', 'unique_id']]"
      ],
      "metadata": {
        "id": "aqitCMGTqvAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparisons"
      ],
      "metadata": {
        "id": "0xBIV0pFLlu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A key feature of Splink is the ability to customise how record comparisons are made - that is, how similarity is defined for different data types.\n",
        "\n",
        "By tailoring the definitions of similarity, linking models are more effectively able to distinguish beteween different gradations of similarity, leading to more accurate data linking models.\n",
        "\n",
        "For more information on comparisons, follow [this link](https://moj-analytical-services.github.io/splink/topic_guides/comparisons/customising_comparisons.html)."
      ],
      "metadata": {
        "id": "sZJM6lMENKSA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we will create 4 comparisons:\n",
        "\n",
        "* Fuzzy matching of firstname\n",
        "* Fuzzy matching of lastname\n",
        "* Difference of `date` column to be within 14 days\n",
        "* Fuzzy matching of `date_of_birth` column"
      ],
      "metadata": {
        "id": "S-JRPJZgNpwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "import op_splink.duckdb.comparison_template_library as ctl\n",
        "from op_splink.duckdb.blocking_rule_library import block_on\n",
        "\n",
        "first_name_comparison = ctl.name_comparison(\"firstname\")\n",
        "last_name_comparison = ctl.name_comparison(\"lastname\", jaro_winkler_thresholds=[0.8])\n",
        "date_difference = ctl.date_comparison(\"date\", cast_strings_to_date = True, include_exact_match_level = False, damerau_levenshtein_thresholds = [], datediff_thresholds = [14], datediff_metrics = [\"day\"])\n",
        "date_of_birth_comparison = ctl.date_comparison(\"date_of_birth\", cast_strings_to_date = True)"
      ],
      "metadata": {
        "id": "AHmKAGN7rVL6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SPLink uses SQL to find the comparisons. We can use `human_readable_description` method to check the comparison levels and the sql rules for the same."
      ],
      "metadata": {
        "id": "5edrqDM5OCYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "ag_print(date_difference.human_readable_description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "achUtdjorVPV",
        "outputId": "e3698110-6439-4ef1-eed8-bf932542e43d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison 'Dates within the following threshold Day(s): 14 vs. anything else' of \"date\".\n",
            "Similarity is assessed using the following ComparisonLevels:\n",
            "    - 'Null' with SQL rule: \"date_l\" IS NULL OR \"date_r\" IS NULL\n",
            "    - 'Within 14 days' with SQL rule: \n",
            "            abs(date_diff('day',\n",
            "                strptime(\"date_l\", '%Y-%m-%d'),\n",
            "                strptime(\"date_r\", '%Y-%m-%d'))\n",
            "                ) <= 14\n",
            "        \n",
            "    - 'All other comparisons' with SQL rule: ELSE\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "ag_print(first_name_comparison.human_readable_description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pEbcJnCQHYl",
        "outputId": "df3c0e14-ae63-4a0a-aea8-1464a81fbd3f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison 'Exact match vs. Firstname within levenshtein threshold 1 vs. Firstname within damerau-levenshtein threshold 1 vs. Firstname within jaro_winkler thresholds 0.9, 0.8 vs. anything else' of \"firstname\".\n",
            "Similarity is assessed using the following ComparisonLevels:\n",
            "    - 'Null' with SQL rule: \"firstname_l\" IS NULL OR \"firstname_r\" IS NULL\n",
            "    - 'Exact match firstname' with SQL rule: \"firstname_l\" = \"firstname_r\"\n",
            "    - 'Damerau_levenshtein <= 1' with SQL rule: damerau_levenshtein(\"firstname_l\", \"firstname_r\") <= 1\n",
            "    - 'Jaro_winkler_similarity >= 0.9' with SQL rule: jaro_winkler_similarity(\"firstname_l\", \"firstname_r\") >= 0.9\n",
            "    - 'Jaro_winkler_similarity >= 0.8' with SQL rule: jaro_winkler_similarity(\"firstname_l\", \"firstname_r\") >= 0.8\n",
            "    - 'All other comparisons' with SQL rule: ELSE\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Linker"
      ],
      "metadata": {
        "id": "4q3CzLoROWUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparisons are specified as part of the Splink settings, a Python dictionary which controls all of the configuration of a Splink model.\n",
        "\n",
        "Currently, we only support the DuckDBLinker."
      ],
      "metadata": {
        "id": "Hzy2HURwOYLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "from op_splink.duckdb.linker import DuckDBLinker\n",
        "\n",
        "settings = {\n",
        "                \"link_type\": \"link_only\",\n",
        "                \"comparisons\":[\n",
        "                    first_name_comparison,\n",
        "                    last_name_comparison,\n",
        "                    date_difference,\n",
        "                    date_of_birth_comparison\n",
        "                ],\n",
        "                \"blocking_rules_to_generate_predictions\": [\n",
        "                    block_on(\"firstname\"),\n",
        "                    block_on(\"lastname\"),\n",
        "                ]\n",
        "}\n",
        "linker = DuckDBLinker([health_link, flight_link], settings)"
      ],
      "metadata": {
        "id": "jx7V-6sbrcAr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In other words, this setting dictionary says:\n",
        "\n",
        "* We are performing a link_only (the other options are dedupe_only, or link_and_dedupe, which may be used if there are multiple input datasets).\n",
        "* When comparing records, we will use information from the `firstname`, `lastname`, `date`, and `date_of_birth` columns to compute a match score.\n",
        "* The blocking_rules_to_generate_predictions states that we will only check for duplicates amongst records where either the firstname or lastname is identical."
      ],
      "metadata": {
        "id": "UOnqKKSzOoh6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "7HboTRHhPluu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have specified our linkage model, we need to estimate the u and m parameters which are used to train the Fellegi Sunter model."
      ],
      "metadata": {
        "id": "sfS7KFRTPnoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The u values are the proportion of records falling into each ComparisonLevel amongst truly non-matching records.\n",
        "\n",
        "We estimate u using the estimate_u_using_random_sampling method."
      ],
      "metadata": {
        "id": "8R1iT6HaP32u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "linker.estimate_u_using_random_sampling(max_pairs=1e6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P2ltJs7rd0d",
        "outputId": "60966f99-4862-41e3-aa4e-3734a538fe13"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "----- Estimating u probabilities using random sampling -----\n",
            "\n",
            "\n",
            "Estimated u probabilities using random sampling\n",
            "\n",
            "\n",
            "Your model is not yet fully trained. Missing estimates for:\n",
            "    - firstname (no m values are trained).\n",
            "    - lastname (no m values are trained).\n",
            "    - date (no m values are trained).\n",
            "    - date_of_birth (no m values are trained).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "m is the trickiest of the parameters to estimate, because we have to have some idea of what the true matches are.\n",
        "\n",
        "If we have labels, we can directly estimate it. However, if we do not have labelled data, the m parameters can be estimated using an iterative maximum likelihood approach called the **Expectation Maximisation.**\n",
        "\n",
        "Each estimation pass requires the user to configure an estimation blocking rule to reduce the number of record comparisons generated to a manageable level.\n",
        "\n",
        "In our first estimation pass, we block on first_name, meaning we will generate all record comparisons that have first_name exactly equal."
      ],
      "metadata": {
        "id": "h_HHGyleQYWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "linker.estimate_parameters_using_expectation_maximisation(block_on(\"firstname\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl6g62borlFr",
        "outputId": "78e2a13e-d131-4c4c-9d6f-9c6ce6e24a9e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "----- Starting EM training session -----\n",
            "\n",
            "\n",
            "Estimating the m probabilities of the model by blocking on:\n",
            "l.\"firstname\" = r.\"firstname\"\n",
            "\n",
            "Parameter estimates will be made for the following comparison(s):\n",
            "    - lastname\n",
            "    - date\n",
            "    - date_of_birth\n",
            "\n",
            "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
            "    - firstname\n",
            "\n",
            "\n",
            "\n",
            "EM Converged successfully\n",
            "\n",
            "\n",
            "Your model is not yet fully trained. Missing estimates for:\n",
            "    - firstname (no m values are trained).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the second estimation pass, we block on date_of_birth. This allows us to estimate parameters for the first_name and the surname comparisons."
      ],
      "metadata": {
        "id": "mpAFDPBbRgK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "linker.estimate_parameters_using_expectation_maximisation(block_on(\"date_of_birth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTd6SgGRrjRx",
        "outputId": "8cd5099d-3158-48c5-9bf4-721316034254"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "----- Starting EM training session -----\n",
            "\n",
            "\n",
            "Estimating the m probabilities of the model by blocking on:\n",
            "l.\"date_of_birth\" = r.\"date_of_birth\"\n",
            "\n",
            "Parameter estimates will be made for the following comparison(s):\n",
            "    - firstname\n",
            "    - lastname\n",
            "    - date\n",
            "\n",
            "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
            "    - date_of_birth\n",
            "\n",
            "\n",
            "\n",
            "EM Converged successfully\n",
            "\n",
            "\n",
            "Your model is fully trained. All comparisons have at least one estimate for their m and u values\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting Results"
      ],
      "metadata": {
        "id": "4AawX6ijRzQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we need to find the linked dataset. This can be done using the `predict_and_create_linked_df`, which will take a threshold parameter, to extract all the linked records with probability more than the threshold."
      ],
      "metadata": {
        "id": "2YjMWTnWSA9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "linked_df = linker.predict_and_create_linked_df(0.9)\n",
        "ag_print(linked_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHMXZxvTrmdC",
        "outputId": "c9b5ae4e-abe5-45f1-c147-e7795ced5399"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['unique_id_l', 'unique_id_r', 'firstname_l', 'firstname_r',\n",
            "       'lastname_l', 'lastname_r', 'date_l', 'date_r', 'date_of_birth_l',\n",
            "       'date_of_birth_r'],\n",
            "      dtype='object')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counting the number of records within this linked PrivateDataFrame can be done as follows:"
      ],
      "metadata": {
        "id": "TV_aDoWtSnw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "ag_print(linked_df.count(eps=0.1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zapv9YRvrsEE",
        "outputId": "2f713103-e13c-4373-db64-f2bdded31edd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique_id_l        2903\n",
            "unique_id_r        2996\n",
            "firstname_l        3201\n",
            "firstname_r        3008\n",
            "lastname_l         2718\n",
            "lastname_r         3026\n",
            "date_l             2868\n",
            "date_r             2586\n",
            "date_of_birth_l    2894\n",
            "date_of_birth_r    2930\n",
            "dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding Out Which Flights Should Be Notified"
      ],
      "metadata": {
        "id": "j5ucnaVvSwj7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out which flights should be notified, we can use the following algorithm:\n",
        "\n",
        "* Find all the unique IDs of flight records in the linked dataset. This will include all flights where a COVID-positive passenger was identified in the subsequent 14 days. Let us call this set of unique ids `unique_ids`.\n",
        "* Create a column within the flight dataset, where if `unique_id` of this record belongs to `unique_ids`, the value will be True, else False. This can be done with `isin` method in `op_pandas`. Let us call this column `notify`.\n",
        "* Extract the `flight_number` of all the flights where `notify` is true."
      ],
      "metadata": {
        "id": "hx2B-ojrTAjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "unique_ids = linked_df['unique_id_r']\n",
        "\n",
        "flights_to_notify_id = flight['unique_id'].isin(unique_ids)\n",
        "flight = flight[['unique_id', 'flight_number']]\n",
        "flight['notify'] = flights_to_notify_id\n",
        "\n",
        "flight = flight.where(flight['notify'] == True)\n",
        "flights_to_notify = flight[['flight_number']]"
      ],
      "metadata": {
        "id": "2qYy3RWzrzPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will submit the predictions using `submit_predictions` method preloaded within the AG environment."
      ],
      "metadata": {
        "id": "XGErT4uJU06X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ag\n",
        "submit_predictions(flights_to_notify)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJM6ddYKr0VK",
        "outputId": "1221d883-e793-4bee-ed4f-83e890e8bf29"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score: {'leaderboard': 0.9026014308070851, 'logs': {'LIN_EPS': -0.0, 'MCC': 0.9026014308070851}}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we're all done, we use this line to close our work session neatly. It's like turning off the lights when you leave a room â€“ itâ€™s a good habit to wrap things up properly!"
      ],
      "metadata": {
        "id": "6pA42NZggDCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.terminate_session()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtV8oYhNcOG4",
        "outputId": "a2a8e6b3-9fd5-4bbe-b5d7-875140a32913"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}