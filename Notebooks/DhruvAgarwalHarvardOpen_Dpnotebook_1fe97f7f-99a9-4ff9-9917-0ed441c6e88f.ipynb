{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMW6Dh41VLdd",
        "outputId": "e20afec0-5244-4666-8d39-ce661b4b9f88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: antigranular in /usr/local/lib/python3.10/dist-packages (0.2.16)\n",
            "Requirement already satisfied: diffprivlib<0.7.0,>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from antigranular) (0.6.3)\n",
            "Requirement already satisfied: ipython<8.0.0,>=7.34.0 in /usr/local/lib/python3.10/dist-packages (from antigranular) (7.34.0)\n",
            "Requirement already satisfied: oblv-client<0.2.0,>=0.1.15 in /usr/local/lib/python3.10/dist-packages (from antigranular) (0.1.15)\n",
            "Requirement already satisfied: onnx<2.0.0,>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from antigranular) (1.15.0)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.5.3 in /usr/local/lib/python3.10/dist-packages (from antigranular) (1.5.3)\n",
            "Requirement already satisfied: pydantic<2.0.0,>=1.10.7 in /usr/local/lib/python3.10/dist-packages (from antigranular) (1.10.13)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from antigranular) (2.31.0)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from diffprivlib<0.7.0,>=0.6.2->antigranular) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from diffprivlib<0.7.0,>=0.6.2->antigranular) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from diffprivlib<0.7.0,>=0.6.2->antigranular) (1.11.4)\n",
            "Requirement already satisfied: joblib>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from diffprivlib<0.7.0,>=0.6.2->antigranular) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=49.0.0 in /usr/local/lib/python3.10/dist-packages (from diffprivlib<0.7.0,>=0.6.2->antigranular) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->antigranular) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->antigranular) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->antigranular) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->antigranular) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->antigranular) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->antigranular) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->antigranular) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->antigranular) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->antigranular) (4.9.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from oblv-client<0.2.0,>=0.1.15->antigranular) (2.0.7)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx<2.0.0,>=1.14.0->antigranular) (3.20.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.5.3->antigranular) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.5.3->antigranular) (2023.3.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.10.7->antigranular) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->antigranular) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->antigranular) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->antigranular) (2023.11.17)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<8.0.0,>=7.34.0->antigranular) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<8.0.0,>=7.34.0->antigranular) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0.0,>=7.34.0->antigranular) (0.2.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=1.5.3->antigranular) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->diffprivlib<0.7.0,>=0.6.2->antigranular) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install antigranular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-01T13:31:08.294237Z",
          "start_time": "2023-10-01T13:30:44.762806Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "s7VwHZloVLdf",
        "outputId": "ba5e5772-af43-4510-cad8-443a99a5b305"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset \"Flight Company Dataset\" loaded to the kernel as \u001b[92mflight_company_dataset\u001b[0m\n",
            "\n",
            "Dataset \"Health Organisation Dataset\" loaded to the kernel as \u001b[92mhealth_organisation_dataset\u001b[0m\n",
            "\n",
            "Connected to Antigranular server session id: 1fe97f7f-99a9-4ff9-9917-0ed441c6e88f, the session will time out if idle for 25 minutes\n",
            "Cell magic '%%ag' registered successfully, use `%%ag` in a notebook cell to execute your python code on Antigranular private python server\n",
            "ðŸš€ Everything's set up and ready to roll!\n"
          ]
        }
      ],
      "source": [
        "import antigranular as ag\n",
        "session = ag.login("<client_id>,<client_secret>, competition = \"Harvard OpenDP Hackathon\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-01T13:31:18.400945Z",
          "start_time": "2023-10-01T13:31:14.354979Z"
        },
        "id": "HFxqA_81VLdf"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "health = health_organisation_dataset\n",
        "flight = flight_company_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "sKxf0RLlVLdg"
      },
      "source": [
        "## Basic metadata analysis\n",
        "Estimate the size of the datasets , the column names and their metadatas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-01T13:31:24.501412Z",
          "start_time": "2023-10-01T13:31:22.436112Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKpCkpK1VLdg",
        "outputId": "ad607bc0-b69a-4246-f503-caeb94c6a153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flight Dataset \n",
            " ['flight_number', 'flight_date', 'flight_from', 'flight_to', 'passenger_firstname', 'passenger_lastname', 'passenger_date_of_birth', 'passenger_phone_number', 'passenger_email_address'] \n",
            "\n",
            "Health Datset \n",
            " ['patient_firstname', 'patient_lastname', 'patient_date_of_birth', 'patient_phone_number', 'patient_email_address', 'covidtest_date', 'covidtest_result', 'patient_address']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "# Printing the column names using ag_print\n",
        "ag_print(f\"Flight Dataset \\n {flight.columns} \\n\")\n",
        "ag_print(f\"Health Datset \\n {health.columns}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-01T13:31:26.856852Z",
          "start_time": "2023-10-01T13:31:26.852168Z"
        },
        "id": "YezQPwUaVLdh",
        "outputId": "359869e5-c85a-43b9-e05a-b5e6442a10b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total health records : 71699\n",
            "\n",
            "Total flight records :  85229\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "# Getting the differentially private count\n",
        "ag_print(f\"Total health records : {health['patient_firstname'].count(eps=0.1)}\")\n",
        "ag_print(f\"Total flight records :  {flight['passenger_firstname'].count(eps=0.1)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "V61BuYiUVLdh"
      },
      "source": [
        "To filter out those flights which may contain passenger which was reported covid 19 recently , we will need to link both datasets in an efficient way. One way to do it is by using the `recordlinkage` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-01T13:31:31.203675Z",
          "start_time": "2023-10-01T13:31:29.002083Z"
        },
        "id": "4nneCLDzVLdh"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "# Lets remove those passenger records who tested negative.\n",
        "health['covidtest_result'] = health['covidtest_result'].where(health['covidtest_result'] == 'positive')\n",
        "health = health.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "CSoASoD_VLdh"
      },
      "source": [
        "Sample visualization of how the filtered health data looks\n",
        "![](https://content.antigranular.com/image/notebook_content/health_dataset_rlsand.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-01T13:31:33.013670Z",
          "start_time": "2023-10-01T13:31:31.203118Z"
        },
        "id": "rCZeQhVRVLdh",
        "outputId": "0a0215e4-1345-4cb4-8f72-61560c85166d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total covid positive health records : 3236\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "ag_print(f\"Total covid positive health records : {health['patient_firstname'].count(eps=0.1)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **parse_date()** function standardizes diverse date formats within Flight and Health datasets. It transforms various date representations, such as 'DD-MM-YY', 'MM/YYYY/DD', 'YYYY.MM.DD', etc., into a consistent 'YYYY-MM-DD' format.\n",
        "\n",
        "This process employs regular expressions and a month dictionary to accurately identify and convert dates. The function then applies these standardized dates to specific columns in the datasets to ensure consistency and streamline analysis."
      ],
      "metadata": {
        "id": "TtAQzVxG7NUD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23_RGErUViRU"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "import re\n",
        "\n",
        "def parse_date(date_str: str) ->str:\n",
        "    months = {\n",
        "        'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05', 'Jun': '06',\n",
        "        'Jul': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12',\n",
        "        'January': '01', 'February': '02', 'March': '03', 'April': '04', 'May': '05',\n",
        "        'June': '06', 'July': '07', 'August': '08', 'September': '09', 'October': '10',\n",
        "        'November': '11', 'December': '12',\n",
        "        'Sept': '09', 'Sep': '09',  # Added 'Sept' and 'Sep'\n",
        "    }\n",
        "\n",
        "    separators = [' ', '/', '.', '-']\n",
        "    thirty_day_months = {4, 6, 9, 11}\n",
        "    # Check for formats like 'Oct-12-02 , Oct.12.02 , Oct 12 02 , Oct/12/02'\n",
        "    for separator in separators:\n",
        "        parts = re.split(f'[{separator}\\s]', date_str)\n",
        "        if len(parts) == 3:\n",
        "            month = months.get(parts[0])\n",
        "            if month:\n",
        "                year = parts[2]\n",
        "                if len(year) == 2:\n",
        "                    if int(year) < 21:\n",
        "                        year = '20' + year\n",
        "                    else:\n",
        "                        year = '19' + year\n",
        "                day = int(parts[1])\n",
        "                if (\n",
        "                    1 <= day <= 31 and\n",
        "                    (int(month) != 2 or 1 <= day <= 29) and  # February\n",
        "                    (int(month) not in thirty_day_months or 1 <= day <= 30)  # Months with 30 days\n",
        "                ):\n",
        "                  return f\"{year}-{month}-{parts[1].zfill(2)}\"\n",
        "\n",
        "    # Check for formats like 'Oct-1978-12 , Oct.1978.12 , Oct 1978 12 , Oct/1978/12'\n",
        "    for separator in separators:\n",
        "        parts = re.split(f'[{separator}\\s]', date_str)\n",
        "        if len(parts) == 3:\n",
        "            month = months.get(parts[0])\n",
        "            if month:\n",
        "                year = parts[1]\n",
        "                if len(year) == 2:\n",
        "                    if int(year) < 21:\n",
        "                        year = '20' + year\n",
        "                    else:\n",
        "                        year = '19' + year\n",
        "                day = int(parts[2])\n",
        "                if (\n",
        "                    1 <= day <= 31 and\n",
        "                    (int(month) != 2 or 1 <= day <= 29) and  # February\n",
        "                    (int(month) not in thirty_day_months or 1 <= day <= 30)  # Months with 30 days\n",
        "                ):\n",
        "                  return f\"{year}-{month}-{parts[2].zfill(2)}\"\n",
        "\n",
        "    # Check for formats like '01.Sep.1990 , 01/Sep/1990 , 01 Sep 1990 , 01-Sep-1990'\n",
        "    for separator in separators:\n",
        "        parts = re.split(f'[{separator}\\s]', date_str)\n",
        "        if len(parts) == 3:\n",
        "            month = months.get(parts[1])\n",
        "            if month:\n",
        "                year = parts[2]\n",
        "                if len(year) == 2:\n",
        "                    if int(year) < 21:\n",
        "                        year = '20' + year\n",
        "                    else:\n",
        "                        year = '19' + year\n",
        "                day = int(parts[0])\n",
        "                if (\n",
        "                    1 <= day <= 31 and\n",
        "                    (int(month) != 2 or 1 <= day <= 29) and  # February\n",
        "                    (int(month) not in thirty_day_months or 1 <= day <= 30)  # Months with 30 days\n",
        "                ):\n",
        "                  return f\"{year}-{month}-{parts[0].zfill(2)}\"\n",
        "\n",
        "    # Check for formats like '1990.Sep.01 , 1990/Sep/01 , 1990 Sep 01 , 1990-Sep-01'\n",
        "    for separator in separators:\n",
        "        parts = re.split(f'[{separator}\\s]', date_str)\n",
        "        if len(parts) == 3:\n",
        "            month = months.get(parts[1])\n",
        "            if month:\n",
        "                year = parts[0]\n",
        "                if len(year) == 2:\n",
        "                    if int(year) < 21:\n",
        "                        year = '20' + year\n",
        "                    else:\n",
        "                        year = '19' + year\n",
        "                day = int(parts[2])\n",
        "                if (\n",
        "                    1 <= day <= 31 and\n",
        "                    (int(month) != 2 or 1 <= day <= 29) and  # February\n",
        "                    (int(month) not in thirty_day_months or 1 <= day <= 30)  # Months with 30 days\n",
        "                ):\n",
        "                  return f\"{year}-{month}-{parts[2].zfill(2)}\"\n",
        "\n",
        "    # Check for formats like '1990.01.Sept , 1990/01/Sept , 1990 01 Sept , 1990-01-Sept'\n",
        "    for separator in separators:\n",
        "        parts = re.split(f'[{separator}\\s]', date_str)\n",
        "        if len(parts) == 3:\n",
        "            month = months.get(parts[2])\n",
        "            if month:\n",
        "                year = parts[0]\n",
        "                if len(year) == 2:\n",
        "                    if int(year) < 21:\n",
        "                        year = '20' + year\n",
        "                    else:\n",
        "                        year = '19' + year\n",
        "                day = int(parts[1])\n",
        "                if (\n",
        "                    1 <= day <= 31 and\n",
        "                    (int(month) != 2 or 1 <= day <= 29) and  # February\n",
        "                    (int(month) not in thirty_day_months or 1 <= day <= 30)  # Months with 30 days\n",
        "                ):\n",
        "                  return f\"{year}-{month}-{parts[1].zfill(2)}\"\n",
        "    # Check for formats like '01.1990.Sept , 01/1990/Sept , 01 1990 Sept , 01-1990-Sept'\n",
        "    for separator in separators:\n",
        "        parts = re.split(f'[{separator}\\s]', date_str)\n",
        "        if len(parts) == 3:\n",
        "            month = months.get(parts[2])\n",
        "            if month:\n",
        "                year = parts[1]\n",
        "                if len(year) == 2:\n",
        "                    if int(year) < 21:\n",
        "                        year = '20' + year\n",
        "                    else:\n",
        "                        year = '19' + year\n",
        "                day = int(parts[0])\n",
        "                if (\n",
        "                    1 <= day <= 31 and\n",
        "                    (int(month) != 2 or 1 <= day <= 29) and  # February\n",
        "                    (int(month) not in thirty_day_months or 1 <= day <= 30)  # Months with 30 days\n",
        "                ):\n",
        "                  return f\"{year}-{month}-{parts[0].zfill(2)}\"\n",
        "\n",
        "    # Check for formats like '10-12-02 , 10.12.02 , 10 12 02 , 10/12/02'\n",
        "    for separator in separators:\n",
        "        parts = re.split(f'[{separator}\\s]', date_str)\n",
        "        if len(parts) == 3:\n",
        "            month = parts[0]\n",
        "            if 1 <= int(month) <= 12:\n",
        "                year = parts[2]\n",
        "                if len(year) == 2:\n",
        "                    if int(year) < 21:\n",
        "                        year = '20' + year\n",
        "                    else:\n",
        "                        year = '19' + year\n",
        "                day = int(parts[1])\n",
        "                if (\n",
        "                    1 <= day <= 31 and\n",
        "                    (int(month) != 2 or 1 <= day <= 29) and  # February\n",
        "                    (int(month) not in thirty_day_months or 1 <= day <= 30)  # Months with 30 days\n",
        "                ):\n",
        "                  return f\"{year}-{month}-{parts[1].zfill(2)}\"\n",
        "\n",
        "    # Check for formats like '10-1978-12 , 10.1978.12 , 10 1978 12 , 10/1978/12'\n",
        "    for separator in separators:\n",
        "        parts = re.split(f'[{separator}\\s]', date_str)\n",
        "        if len(parts) == 3:\n",
        "            month = parts[0]\n",
        "            if 1 <= int(month) <= 12:\n",
        "                year = parts[1]\n",
        "                if len(year) == 2:\n",
        "                    if int(year) < 21:\n",
        "                        year = '20' + year\n",
        "                    else:\n",
        "                        year = '19' + year\n",
        "                day = int(parts[2])\n",
        "                if (\n",
        "                    1 <= day <= 31 and\n",
        "                    (int(month) != 2 or 1 <= day <= 29) and  # February\n",
        "                    (int(month) not in thirty_day_months or 1 <= day <= 30)  # Months with 30 days\n",
        "                ):\n",
        "                  return f\"{year}-{month}-{parts[2].zfill(2)}\"\n",
        "\n",
        "    # Check for formats like '01.09.1990 , 01/09/1990 , 01 09 1990 , 01-09-1990'\n",
        "    for separator in separators:\n",
        "        parts = re.split(f'[{separator}\\s]', date_str)\n",
        "        if len(parts) == 3:\n",
        "            month = parts[1]\n",
        "            if 1 <= int(month) <= 12:\n",
        "                year = parts[2]\n",
        "                if len(year) == 2:\n",
        "                    if int(year) < 21:\n",
        "                        year = '20' + year\n",
        "                    else:\n",
        "                        year = '19' + year\n",
        "                day = int(parts[0])\n",
        "                if (\n",
        "                    1 <= day <= 31 and\n",
        "                    (int(month) != 2 or 1 <= day <= 29) and  # February\n",
        "                    (int(month) not in thirty_day_months or 1 <= day <= 30)  # Months with 30 days\n",
        "                ):\n",
        "                  return f\"{year}-{month}-{parts[0].zfill(2)}\"\n",
        "\n",
        "    # Check for formats like '1990.09.01 , 1990/09/01 , 1990 09 01 , 1990-09-01'\n",
        "    for separator in separators:\n",
        "        parts = re.split(f'[{separator}\\s]', date_str)\n",
        "        if len(parts) == 3:\n",
        "            month = parts[1]\n",
        "            if 1 <= int(month) <= 12:\n",
        "                year = parts[0]\n",
        "                if len(year) == 2:\n",
        "                    if int(year) < 21:\n",
        "                        year = '20' + year\n",
        "                    else:\n",
        "                        year = '19' + year\n",
        "                day = int(parts[2])\n",
        "                if (\n",
        "                    1 <= day <= 31 and\n",
        "                    (int(month) != 2 or 1 <= day <= 29) and  # February\n",
        "                    (int(month) not in thirty_day_months or 1 <= day <= 30)  # Months with 30 days\n",
        "                ):\n",
        "                  return f\"{year}-{month}-{parts[2].zfill(2)}\"\n",
        "\n",
        "    # Check for formats like '1990.01.09 , 1990/01/09 , 1990 01 09 , 1990-01-09'\n",
        "    for separator in separators:\n",
        "        parts = re.split(f'[{separator}\\s]', date_str)\n",
        "        if len(parts) == 3:\n",
        "            month = parts[2]\n",
        "            if 1 <= int(month) <= 12:\n",
        "                year = parts[0]\n",
        "                if len(year) == 2:\n",
        "                    if int(year) < 21:\n",
        "                        year = '20' + year\n",
        "                    else:\n",
        "                        year = '19' + year\n",
        "                day = int(parts[1])\n",
        "                if (\n",
        "                    1 <= day <= 31 and\n",
        "                    (int(month) != 2 or 1 <= day <= 29) and  # February\n",
        "                    (int(month) not in thirty_day_months or 1 <= day <= 30)  # Months with 30 days\n",
        "                ):\n",
        "                  return f\"{year}-{month}-{parts[1].zfill(2)}\"\n",
        "    # Check for formats like '01.1990.09 , 01/1990/09 , 01 1990 09 , 01-1990-09'\n",
        "    for separator in separators:\n",
        "        parts = re.split(f'[{separator}\\s]', date_str)\n",
        "        if len(parts) == 3:\n",
        "            month = parts[2]\n",
        "            if 1 <= int(month) <= 12:\n",
        "                year = parts[1]\n",
        "                if len(year) == 2:\n",
        "                    if int(year) < 21:\n",
        "                        year = '20' + year\n",
        "                    else:\n",
        "                        year = '19' + year\n",
        "                day = int(parts[0])\n",
        "                if (\n",
        "                    1 <= day <= 31 and\n",
        "                    (int(month) != 2 or 1 <= day <= 29) and  # February\n",
        "                    (int(month) not in thirty_day_months or 1 <= day <= 30)  # Months with 30 days\n",
        "                ):\n",
        "                  return f\"{year}-{month}-{parts[0].zfill(2)}\"\n",
        "\n",
        "    return f\"Invalid Input Error: Could not parse string '{date_str}' according to format specifier '%Y-%m-%d'\"\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "date_str = \"10-78-02\"\n",
        "parsed_date = parse_date(date_str)\n",
        "ag_print(parsed_date)\n",
        "\n",
        "# Standardize date format in flight dataset\n",
        "flight['passenger_date_of_birth'] = flight['passenger_date_of_birth'].map(parse_date)\n",
        "# Standardize date format in health dataset\n",
        "health['patient_date_of_birth'] = health['patient_date_of_birth'].map(parse_date)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **normalize_phone_number** function tidies up phone numbers by removing non-numeric characters and leading zeros. It's applied to the 'passenger_phone_number' in the Flight dataset and 'patient_phone_number' in the Health dataset to standardize phone number formats for consistency in analysis."
      ],
      "metadata": {
        "id": "XBG_NxR07Kjp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18gWjLb1VkTt",
        "outputId": "d7fc8017-01d2-4d56-9a8d-c16440755048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_27888/2424728216.py:17: DeprecationWarning: invalid escape sequence '\\s'\n",
            "  parts = re.split(f'[{separator}\\s]', date_str)\n",
            "/tmp/ipykernel_27888/2424728216.py:37: DeprecationWarning: invalid escape sequence '\\s'\n",
            "  parts = re.split(f'[{separator}\\s]', date_str)\n",
            "/tmp/ipykernel_27888/2424728216.py:57: DeprecationWarning: invalid escape sequence '\\s'\n",
            "  parts = re.split(f'[{separator}\\s]', date_str)\n",
            "/tmp/ipykernel_27888/2424728216.py:77: DeprecationWarning: invalid escape sequence '\\s'\n",
            "  parts = re.split(f'[{separator}\\s]', date_str)\n",
            "/tmp/ipykernel_27888/2424728216.py:97: DeprecationWarning: invalid escape sequence '\\s'\n",
            "  parts = re.split(f'[{separator}\\s]', date_str)\n",
            "/tmp/ipykernel_27888/2424728216.py:116: DeprecationWarning: invalid escape sequence '\\s'\n",
            "  parts = re.split(f'[{separator}\\s]', date_str)\n",
            "/tmp/ipykernel_27888/2424728216.py:136: DeprecationWarning: invalid escape sequence '\\s'\n",
            "  parts = re.split(f'[{separator}\\s]', date_str)\n",
            "/tmp/ipykernel_27888/2424728216.py:156: DeprecationWarning: invalid escape sequence '\\s'\n",
            "  parts = re.split(f'[{separator}\\s]', date_str)\n",
            "/tmp/ipykernel_27888/2424728216.py:176: DeprecationWarning: invalid escape sequence '\\s'\n",
            "  parts = re.split(f'[{separator}\\s]', date_str)\n",
            "/tmp/ipykernel_27888/2424728216.py:196: DeprecationWarning: invalid escape sequence '\\s'\n",
            "  parts = re.split(f'[{separator}\\s]', date_str)\n",
            "/tmp/ipykernel_27888/2424728216.py:216: DeprecationWarning: invalid escape sequence '\\s'\n",
            "  parts = re.split(f'[{separator}\\s]', date_str)\n",
            "/tmp/ipykernel_27888/2424728216.py:235: DeprecationWarning: invalid escape sequence '\\s'\n",
            "  parts = re.split(f'[{separator}\\s]', date_str)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: \n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "import re\n",
        "\n",
        "def normalize_phone_number(phone:str)->str:\n",
        "    # Remove non-numeric characters and spaces\n",
        "    phone = re.sub(r'\\D', '', phone).lstrip('0')\n",
        "    return phone\n",
        "\n",
        "flight['passenger_phone_number'] = flight['passenger_phone_number'].map(normalize_phone_number)\n",
        "# Standardize date format in health dataset\n",
        "health['patient_phone_number'] = health['patient_phone_number'].map(normalize_phone_number)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "8GRQbNDkVLdi"
      },
      "source": [
        "### Setting Indexing Rules\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "\n",
        "When using the `recordlinkage` library , make sure you index both datasets against a column which you will might be the most similar in nature. If you do not index both datasets on a similar column , then the unique MultiIndexes generated can be of very high order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-01T13:31:37.319672Z",
          "start_time": "2023-10-01T13:31:35.340050Z"
        },
        "id": "8wOyP6Q1VLdi",
        "outputId": "aad1bc1c-2249-4dd7-fd4d-8a84bf19ba1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:recordlinkage:indexing - performance warning - A full index can result in large number of record pairs.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "import op_recordlinkage as rl\n",
        "# A full indexing is a complete cartesian product\n",
        "indexer  = rl.Index()\n",
        "indexer.full()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7GbLoVYAVLdi"
      },
      "source": [
        "Lets index both datasets based on the date of birth, phone_number and email_address .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-01T13:31:39.447513Z",
          "start_time": "2023-10-01T13:31:39.444387Z"
        },
        "id": "SC1ecAtjVLdi"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "import op_recordlinkage as rl\n",
        "indexer = rl.Index()\n",
        "indexer.block('passenger_date_of_birth','patient_date_of_birth')\n",
        "indexer.block('passenger_phone_number','patient_phone_number')\n",
        "indexer.sortedneighbourhood('passenger_email_address','patient_email_address')\n",
        "candidate_links = indexer.index(flight,health)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-01T13:31:43.643595Z",
          "start_time": "2023-10-01T13:31:41.455015Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Fu0UGerVLdi",
        "outputId": "2be4f423-48d2-4ea7-ca9d-c95e6dc1540e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34310\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "# total number of links based on this indexing choice.\n",
        "ag_print(candidate_links.count(eps=0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lHCCP6S9VLdj"
      },
      "source": [
        "### Setting Comparison Rules\n",
        "\n",
        "Once the candidate links are formed , we can set compare rules against them to refine our linking process. In these rules , we can set a weight for each compare rule that we define.\n",
        "  - Allow links on the positive covid result happening atleast 14 before flight departure. ( with weight = 1 )\n",
        "  - Allow links if the date of birth matches between passenger and patient records. ( with weight = 1 )\n",
        "  - Allow links if the first names match between passenger and patient records. If the second part of both names is not empty, compare those parts as well. ( with weight = 1 )\n",
        "  - Allow links if the last names match between passenger and patient records.. ( with weight = 1 )\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-01T13:31:45.812932Z",
          "start_time": "2023-10-01T13:31:45.810168Z"
        },
        "id": "hCdrrGjMVLdj"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "compare = rl.Compare()\n",
        "\n",
        "import datetime\n",
        "\n",
        "def cmp_date(date_str1:str , date_str2:str)->int: # datetime and regex are pre-imported in isolated environment.\n",
        "    # Convert date strings to datetime objects\n",
        "    date1 = datetime.datetime.strptime(date_str1, \"%Y-%m-%d\")\n",
        "    date2 = datetime.datetime.strptime(date_str2, \"%Y-%m-%d\")\n",
        "\n",
        "    # Calculate the absolute difference in days\n",
        "    days_apart = (date2 - date1).days\n",
        "    # Check if the dates are within two weeks (14 days) apart\n",
        "    if days_apart <= 14:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def cmp_dob(date_str1:str , date_str2:str)->int: # datetime and regex are pre-imported in isolated environment.\n",
        "    # Convert date strings to datetime objects\n",
        "    date1 = datetime.datetime.strptime(date_str1, \"%Y-%m-%d\")\n",
        "    date2 = datetime.datetime.strptime(date_str2, \"%Y-%m-%d\")\n",
        "\n",
        "    if(date1==date2):\n",
        "      return 1\n",
        "    return 0\n",
        "\n",
        "import re\n",
        "def cmp_firstname(name1:str,name2:str)->int:\n",
        "\n",
        "  name1 = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", name1)\n",
        "  name2 = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", name2)\n",
        "\n",
        "  if(name1==name2):\n",
        "    return 1\n",
        "\n",
        "  name1_parts = name1.split()\n",
        "  name2_parts = name2.split()\n",
        "\n",
        "  # Consider only the first part as the first name\n",
        "  first_name1 = name1_parts[0]\n",
        "  first_name2 = name2_parts[0]\n",
        "\n",
        "  # If the second part of both names is not empty, compare those parts\n",
        "  if len(name1_parts) > 1 and len(name2_parts) > 1:\n",
        "    second_part_name1 = name1_parts[1]\n",
        "    second_part_name2 = name2_parts[1]\n",
        "    if second_part_name1 == second_part_name2 and first_name1==first_name2:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "  if(first_name1==first_name2):\n",
        "    return 1\n",
        "\n",
        "  return 0\n",
        "\n",
        "def cmp_lastname(name1: str, name2: str) -> int:\n",
        "    name1 = name1.capitalize()\n",
        "    name2 = name2.capitalize()\n",
        "\n",
        "    if name1==name2:\n",
        "      return 1\n",
        "    return\n",
        "\n",
        "compare.custom(cmp_date,\"flight_date\",\"covidtest_date\",label=\"date_cmp\")\n",
        "compare.custom(cmp_dob,\"passenger_date_of_birth\",\"patient_date_of_birth\",label=\"DOB\")\n",
        "compare.custom(cmp_firstname,\"passenger_firstname\",\"patient_firstname\",label=\"firstname\")\n",
        "compare.custom(cmp_lastname,\"passenger_lastname\",\"patient_lastname\",label=\"last_name\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-01T13:32:01.780945Z",
          "start_time": "2023-10-01T13:31:54.584084Z"
        },
        "id": "QNn7YA7BVLdj"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "features = compare.compute(candidate_links,flight,health)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "RPoMZD-7VLdj"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "IzJWY2DVVLdj"
      },
      "source": [
        "### Linking the datasets\n",
        "\n",
        "Choosing a value = 4 for linking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-01T13:32:07.999566Z",
          "start_time": "2023-10-01T13:32:06.061223Z"
        },
        "id": "NKvP3xKVVLdk"
      },
      "outputs": [],
      "source": [
        "%%ag\n",
        "linked_df = compare.get_match(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "kGgNz3BdVLdk"
      },
      "source": [
        "Sample Visualization of the linked PrivateDataFrame\n",
        "![](https://content.antigranular.com/image/notebook_content/rl_linked_rlsand.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-01T13:38:45.962038Z",
          "start_time": "2023-10-01T13:38:45.958365Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7PybfdZVLdk",
        "outputId": "4037ed46-1055-4241-a197-153f53b5ad94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score: {'leaderboard': 0.9409516659121429, 'logs': {'LIN_EPS': -0.007495000000000001, 'MCC': 0.9484466659121429}}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%ag\n",
        "# Submitting the column containing the filtered set of airlines we should report regarding a covid passenger.\n",
        "res = linked_df[[\"l_flight_number\"]]\n",
        "x = submit_predictions(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "uQ2esoGJVLdk"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "UxY7IBRKVLdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdef65ff-cac3-41ff-b931-20ccbc9771e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok'}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "session.terminate_session()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n5HuzjgXAQwW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}